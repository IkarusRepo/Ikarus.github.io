{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the documentation of Ikarus \u00b6 Ikarus is a finite element software originated at the Institute for Structural Mechanics at the university of Stuttgart. This project tries to provide an easy to read and an easy to use finite element framework. It is heavily inspired by the finite element softwares DUNE , the book DUNE \u2014 The Distributed and Unified Numerics Environment , deal.II and Kratos . Furthermore it directly used several modules from DUNE . We favor value semantics and readability. Concerning the design of CI and the documentation we were inspired by Autodiff and Kratos . The documentation is build using Material for MkDocs .","title":"Home"},{"location":"#welcome-to-the-documentation-of-ikarus","text":"Ikarus is a finite element software originated at the Institute for Structural Mechanics at the university of Stuttgart. This project tries to provide an easy to read and an easy to use finite element framework. It is heavily inspired by the finite element softwares DUNE , the book DUNE \u2014 The Distributed and Unified Numerics Environment , deal.II and Kratos . Furthermore it directly used several modules from DUNE . We favor value semantics and readability. Concerning the design of CI and the documentation we were inspired by Autodiff and Kratos . The documentation is build using Material for MkDocs .","title":"Welcome to the documentation of Ikarus"},{"location":"AdvancedTopics/","text":"Advanced topics \u00b6 The following topics are probably not relevant for your daily work, but you might need this knowledge at some point. Add additional dependencies or update existing dependencies to a newer version \u00b6 All the dependencies of Ikarus are shipped in a docker container. The corresponding docker image is available at https://github.com/IkarusRepo/DockerContainer . In order to modify the dependencies, you need to create a modified version of this dockerfile, create a new docker container and execute your code in this docker container (i.e. change the docker image to be used in the CLion settings).","title":"Advanced Topics"},{"location":"AdvancedTopics/#advanced-topics","text":"The following topics are probably not relevant for your daily work, but you might need this knowledge at some point.","title":"Advanced topics"},{"location":"AdvancedTopics/#add-additional-dependencies-or-update-existing-dependencies-to-a-newer-version","text":"All the dependencies of Ikarus are shipped in a docker container. The corresponding docker image is available at https://github.com/IkarusRepo/DockerContainer . In order to modify the dependencies, you need to create a modified version of this dockerfile, create a new docker container and execute your code in this docker container (i.e. change the docker image to be used in the CLion settings).","title":"Add additional dependencies or update existing dependencies to a newer version"},{"location":"codeStyle/","text":"Code style \u00b6 This section explains the theoretical background and implementation details of various parts of the code. It is dedicated to users who want to extend or modify the implemented functionality or who want to learn more about the implementation thoughts and theoretical aspects. The directories and filenames use camelCase The source files have a cpp extension and the header files hh . We also use a clang-format file which needs to be executed in each file before a PR can be merged For comments in the code we follow: Quote of Robert Martin in VideoLink \"The proper use of comments is: To compensate for our failure to express ourselves in code.\" Thus, lots of comments should not be interpreted as good programming style but they should be sign as a failure to express ourselves. Programming style \u00b6 Seperation of interface and implementation \u00b6 On many of the theory pages you will find a description of an interface and a discussion of the implementation. What interface and implementation means is explained here with the example of a car. Interface of a car \u00b6 Let's first define the interface of a car. A car is from a certain brand and it has a maximum velocity. The interface of a car is then: brand() : a function which returns the brand as a string maxvelocity() : a function which returns the maximum velocity as a double This can be written in a more formalized way, e.g. as a C++20 concept, but we currently write it in this documentation as shown above. Everything that wants to be a car has to have a member function brand() which returns a string and a member function maxVeloctiy() which returns a double. Implementation of a car \u00b6 Let's now implement a car. class MyCar { public : std :: string brand () { return \"MyBrand\" ;} double maxVelocity () { double velocity ; // calculate maximum velocity with some complicated calculations return velocity ; } }; The class MyCar fulfills the car interface and is a therefore considered a car. There can be many classes that fulfill the car interface, e.g. someone else could arrive and implement class AnotherCar . Summary \u00b6 Interface: Defines a set of requirements Implementation: A specific class which fulfills the interface Member functions and free functions \u00b6 In this documentation, we also list free functions as a part of the interface. This is indicated by the arguments in the list of interface functions. An example: If there is something like brand(car) in the interface list, this means that there has to be a function which gets a car object as argument and returns the name of the brand. An implementation for MyCar then looks like this: std :: string brand ( MyCar carObject ) { return \"MyBrand\" ;} This function is called a free function because it isn't part of the class MyCar but it is free (and could be defined in another file then the class MyCar).","title":"Code style"},{"location":"codeStyle/#code-style","text":"This section explains the theoretical background and implementation details of various parts of the code. It is dedicated to users who want to extend or modify the implemented functionality or who want to learn more about the implementation thoughts and theoretical aspects. The directories and filenames use camelCase The source files have a cpp extension and the header files hh . We also use a clang-format file which needs to be executed in each file before a PR can be merged For comments in the code we follow: Quote of Robert Martin in VideoLink \"The proper use of comments is: To compensate for our failure to express ourselves in code.\" Thus, lots of comments should not be interpreted as good programming style but they should be sign as a failure to express ourselves.","title":"Code style"},{"location":"codeStyle/#programming-style","text":"","title":"Programming style"},{"location":"codeStyle/#seperation-of-interface-and-implementation","text":"On many of the theory pages you will find a description of an interface and a discussion of the implementation. What interface and implementation means is explained here with the example of a car.","title":"Seperation of interface and implementation"},{"location":"codeStyle/#interface-of-a-car","text":"Let's first define the interface of a car. A car is from a certain brand and it has a maximum velocity. The interface of a car is then: brand() : a function which returns the brand as a string maxvelocity() : a function which returns the maximum velocity as a double This can be written in a more formalized way, e.g. as a C++20 concept, but we currently write it in this documentation as shown above. Everything that wants to be a car has to have a member function brand() which returns a string and a member function maxVeloctiy() which returns a double.","title":"Interface of a car"},{"location":"codeStyle/#implementation-of-a-car","text":"Let's now implement a car. class MyCar { public : std :: string brand () { return \"MyBrand\" ;} double maxVelocity () { double velocity ; // calculate maximum velocity with some complicated calculations return velocity ; } }; The class MyCar fulfills the car interface and is a therefore considered a car. There can be many classes that fulfill the car interface, e.g. someone else could arrive and implement class AnotherCar .","title":"Implementation of a car"},{"location":"codeStyle/#summary","text":"Interface: Defines a set of requirements Implementation: A specific class which fulfills the interface","title":"Summary"},{"location":"codeStyle/#member-functions-and-free-functions","text":"In this documentation, we also list free functions as a part of the interface. This is indicated by the arguments in the list of interface functions. An example: If there is something like brand(car) in the interface list, this means that there has to be a function which gets a car object as argument and returns the name of the brand. An implementation for MyCar then looks like this: std :: string brand ( MyCar carObject ) { return \"MyBrand\" ;} This function is called a free function because it isn't part of the class MyCar but it is free (and could be defined in another file then the class MyCar).","title":"Member functions and free functions"},{"location":"cppRef/","text":"C++ recommendations \u00b6 As you may know by now Ikarus is written in C++. On this page we summerize recommendation to dig deeper into C++ coding. Should i write a member function or a free- function? \u00b6 Scott Meyers recommends the following algorithm: Link When to use const? \u00b6 Arthur O'Dwyer blog How should i pass my parameters to a function and return from a function? \u00b6 Herb Sutter Cppcon Talk 2014 Best practices \u00b6 C++ Core Guidelines (A lot to learn there and you can just search some topic.) Jason Turner's collection of best practices More C++ idioms Further references \u00b6 Cppcon Videos These videos are released after every conference. For beginners the Back to basics track can be recommended. Godblot Online compiler with assembler output. Nice to test fast if something would be fast or slow. Also Eigen can be added. Also any other header found on the internet can be include with the link. Videos \u00b6 Here we collect usefull videos on coding or coding c++: Clean Code - Uncle Bob / Lesson 1 How to write code cleanly, see also 1 CppCon 2014: Herb Sutter \"Back to the Basics! Essentials of Modern C++ Style\" CppCon 2018: Jonathan Boccara \u201c105 STL Algorithms in Less Than an Hour\u201d \"Almost\" all algorithms in the STL Back to Basics: Object-Oriented Programming - Jon Kalb - CppCon 2019 How to do modern \"Object-Oriented Programming\" (If you really have to) [CppCon 2021 - Back To Basics] ( https://www.youtube.com/watch?v=Bt3zcJZIalk&list=PLHTh1InhhwT4TJaHBVWzvBOYhp27UO7mI ) CppCon 2019 Back to Basics Books \u00b6 2 3 4 5 Robert C Martin. Clean Code . Pearson Education, 2008. \u21a9 Erich Gamma, Richard Helm, Ralph Johnson, Ralph E Johnson, John Vlissides, and others. Design patterns: elements of reusable object-oriented software . Pearson Deutschland GmbH, 1995. \u21a9 Martin Reddy. API Design for C++ . Elsevier, 2011. \u21a9 Scott Meyers. Effective C++: 55 specific ways to improve your programs and designs . Pearson Education, 2005. \u21a9 Scott Meyers. More Effective C++: 35 New Ways to Improve Your Programs and Designs, PDF Version . Pearson Education, 1995. \u21a9","title":"C++ recommendations"},{"location":"cppRef/#c-recommendations","text":"As you may know by now Ikarus is written in C++. On this page we summerize recommendation to dig deeper into C++ coding.","title":"C++ recommendations"},{"location":"cppRef/#should-i-write-a-member-function-or-a-free-function","text":"Scott Meyers recommends the following algorithm: Link","title":"Should i write a member function or a free- function?"},{"location":"cppRef/#when-to-use-const","text":"Arthur O'Dwyer blog","title":"When to use const?"},{"location":"cppRef/#how-should-i-pass-my-parameters-to-a-function-and-return-from-a-function","text":"Herb Sutter Cppcon Talk 2014","title":"How should i pass my parameters to a function and return from a function?"},{"location":"cppRef/#best-practices","text":"C++ Core Guidelines (A lot to learn there and you can just search some topic.) Jason Turner's collection of best practices More C++ idioms","title":"Best practices"},{"location":"cppRef/#further-references","text":"Cppcon Videos These videos are released after every conference. For beginners the Back to basics track can be recommended. Godblot Online compiler with assembler output. Nice to test fast if something would be fast or slow. Also Eigen can be added. Also any other header found on the internet can be include with the link.","title":"Further references"},{"location":"cppRef/#videos","text":"Here we collect usefull videos on coding or coding c++: Clean Code - Uncle Bob / Lesson 1 How to write code cleanly, see also 1 CppCon 2014: Herb Sutter \"Back to the Basics! Essentials of Modern C++ Style\" CppCon 2018: Jonathan Boccara \u201c105 STL Algorithms in Less Than an Hour\u201d \"Almost\" all algorithms in the STL Back to Basics: Object-Oriented Programming - Jon Kalb - CppCon 2019 How to do modern \"Object-Oriented Programming\" (If you really have to) [CppCon 2021 - Back To Basics] ( https://www.youtube.com/watch?v=Bt3zcJZIalk&list=PLHTh1InhhwT4TJaHBVWzvBOYhp27UO7mI ) CppCon 2019 Back to Basics","title":"Videos"},{"location":"cppRef/#books","text":"2 3 4 5 Robert C Martin. Clean Code . Pearson Education, 2008. \u21a9 Erich Gamma, Richard Helm, Ralph Johnson, Ralph E Johnson, John Vlissides, and others. Design patterns: elements of reusable object-oriented software . Pearson Deutschland GmbH, 1995. \u21a9 Martin Reddy. API Design for C++ . Elsevier, 2011. \u21a9 Scott Meyers. Effective C++: 55 specific ways to improve your programs and designs . Pearson Education, 2005. \u21a9 Scott Meyers. More Effective C++: 35 New Ways to Improve Your Programs and Designs, PDF Version . Pearson Education, 1995. \u21a9","title":"Books"},{"location":"download/","text":"Installation of Ikarus \u00b6 Change links on this website when final accounts for repository and docker container are fixed and remove this warning. Graphical output is currently not supported on Windows 10 (but will probably be available in the future). Therefore, working on Windows 11 is recommended. The installations on Windows relies on WSL 2, i.e. although working with Windows, the code is compiled and executed in Linux. Installation on Windows using Docker Container \u00b6 Install WSL: Open the PowerShell as an admin and execute the following commands. Reboot afterwards, if requested. wsl --install wsl --set-default-version 2 #(Is not needed for Windows 11) Download and install Docker for Windows . During the installation, select the option \"Install requred Windows components for WSL 2\" Install debian from WindowsAppStore Open the debian app Give yourself a username and password Close the debian app Open the PowerShell and execute: wsl --list --all Debian should appear as one of the available Linux distributions. In the PowerShell execute: wsl --setdefault Debian Try to start Docker. If it works, continue with the next step. If a message occurs that you are not allowed to use docker because you are not in the docker user group, follow these instructions . In short: Open Computerverwaltung as admin Go to Lokale Benutzer und Gruppen and find docker-users Add your Account (or a group of which you are a member) to the group. Restart your computer In Docker, go to Settings \u2192 General and select autostart for docker (otherwise you have to start it manually each time you want to work with Ikarus). In the Docker settings, select that Docker uses your WSL2 distribution Debian as shown in the picture. In cases docker says that you don't have a WSL 2 distribution, go to the PowerShell and execute wsl --set-default-version 2 #(just to be sure that you didn't forgot this at the beginning) wsl --set-version Debian 2 #(Converts debian to version 2) You should now be able to change the docker settings according to the picture above. Open the PowerShell and execute: docker pull rath3t/ikarus-debian-bookworm:latest Download and install CLion . You need a version >=2022.1. In CLion, go to File and Settings and apply the following settings for the toolchain: Edit the Container settings and paste the following command into Run options : -e DISPLAY=:0 -v \\\\wsl$\\debian\\mnt\\wslg\\.X11-unix:/tmp/.X11-unix -v \\\\wsl$\\debian\\mnt\\wslg:/mnt/wslg --cap-add=SYS_PTRACE Clone Ikarus Clone Ikarus \u00b6 Clone the Ikarus repository as you do it with any other repository (e.g. using GitKraken) ToDo: Describe here how to access it from Github.com Open the CMake tab CMake in the CLion footer: Click on Reload CMake project (refresh symbol) CMake now detects all required sources automatically. The output should look similar to the screenshot below Installation on Windows using WSL \u00b6 This installation procedure is not recommended The installation using Docker described above has several advantages and should be the standard. This section will be removed in the future Install WSL: Open the PowerShell as an admin and execute the following commands. Reboot afterwards, if requested. wsl --install wsl --set-default-version 2 #(Is not needed for Windows 11) Install debian from .tar file OR alternatively (3) wsl --import debian <install location> debian_bookworm.tar Install debian manually Install from WindowsAppStore Open the debian app Give yourself a username and password Execute in debian sudo sed -i 's/bullseye/bookworm/g' /etc/apt/sources.list Execute the following list of commands in debian sudo apt update && \\ sudo apt full-upgrade -y && \\ sudo apt -y install lsb-release && \\ sudo apt -y install build-essential \\ libssl-dev \\ git \\ wget \\ apt-utils \\ software-properties-common \\ gfortran \\ gcc-11 \\ g++-11 \\ gcovr \\ clang \\ libmetis-dev \\ clang-tidy \\ libclang-13-dev \\ clang-format-13 \\ libc++-13-dev \\ libc++abi-13-dev \\ llvm-13-dev \\ liblapack-dev \\ libopenblas-dev \\ libsuitesparse-dev \\ libdune-common-dev \\ libdune-geometry-dev \\ libdune-grid-dev \\ libdune-functions-dev \\ libdune-typetree-dev \\ libdune-localfunctions-dev \\ libdune-uggrid-dev \\ libdune-grid-glue-dev \\ libdune-istl-dev \\ libspdlog-dev \\ libbenchmark-dev \\ libgtest-dev \\ gnuplot \\ python3 \\ pip \\ clang-format-12 \\ gnuplot-x11 \\ curl \\ cppcheck && \\ sudo apt-get install libayatana-appindicator3-1 -y && \\ sudo apt-get -y -f install && \\ sudo apt install libasound2 xvfb -y && \\ wget https://github.com/jgraph/drawio-desktop/releases/download/v16.5.1/drawio-amd64-16.5.1.deb && \\ sudo dpkg -i drawio-amd64-16.5.1.deb && \\ pip install cmakelang == 0 .6.13 pyyaml && \\ pip install mkdocs && \\ pip install mkdocs-material && \\ pip install mkdocs-macros-plugin && \\ pip install mkdocs-drawio-exporter && \\ && \\ sudo cp /usr/bin/clang-format-12 /usr/bin/clang-format && \\ cd /usr/local/bin && \\ sudo ln -s $HOME /.local/bin/cmake-format cmake-format && \\ sudo ln -s $HOME /.local/bin/mkdocs mkdocs && \\ cd ~ && \\ mkdir -p iwyu && \\ cd iwyu && \\ git clone https://github.com/include-what-you-use/include-what-you-use.git && \\ cd include-what-you-use && \\ git checkout clang_13 && \\ cd .. && \\ mkdir -p build && cd build && \\ cmake -G \"Unix Makefiles\" -DIWYU_LLVM_ROOT_PATH = /usr/lib/llvm-13 ../include-what-you-use && \\ make && \\ sudo make install && \\ cd /usr/src/googletest && \\ cmake . && \\ sudo cmake --build . --target install && \\ cd ~ && \\ git clone https://gitlab.com/libeigen/eigen.git && \\ cd eigen && \\ git checkout 3 .4 && \\ mkdir build && \\ cd build && \\ cmake ../ && \\ sudo make install && \\ cd ~ && \\ rm -rf eigen && \\ git clone https://github.com/alandefreitas/matplotplusplus.git && \\ cd matplotplusplus && \\ mkdir -p build && \\ cd build && \\ cmake .. -DCMAKE_BUILD_TYPE = Release -DBUILD_EXAMPLES = OFF -DBUILD_TESTS = OFF && \\ cmake --build . --parallel 4 --config Release && \\ sudo cmake --install . && \\ cd ~ && \\ rm -rf matplotplusplus && \\ git clone https://github.com/autodiff/autodiff && \\ cd autodiff/ && \\ mkdir .build && \\ cd .build/ && \\ cmake .. -DAUTODIFF_BUILD_PYTHON = 0 -DAUTODIFF_BUILD_EXAMPLES = 0 -DAUTODIFF_BUILD_DOCS = 0 -DAUTODIFF_BUILD_TESTS = 0 && \\ sudo cmake --build . --target install && \\ cd ../.. && \\ mkdir -p dune && \\ cd dune && \\ git clone https://gitlab.dune-project.org/extensions/dune-alugrid.git && \\ git clone https://gitlab.dune-project.org/extensions/dune-foamgrid.git && \\ dunecontrol git checkout releases/2.8 && \\ git clone https://github.com/rath3t/dune-iga.git && \\ dunecontrol cmake \"-DCMAKE_BUILD_TYPE=Release\" && \\ dunecontrol make && \\ sudo dunecontrol make install && \\ cd .. && \\ rm -rf dune && \\ sudo apt-get auto-remove -y && \\ sudo apt-get clean wget https://raw.githubusercontent.com/JetBrains/clion-wsl/master/ubuntu_setup_env.sh && bash ubuntu_setup_env.sh In Clion, go to File and Settings and apply the following settings for the toolchain: Build, Execution, Deployment \u2192 Toolchains: Add with the + -sign a WSL configuration Make sure it is used as defaultm i.e. it has to be the first item in the list. Move it up with the arrow buttons otherwise.","title":"Download"},{"location":"download/#installation-of-ikarus","text":"Change links on this website when final accounts for repository and docker container are fixed and remove this warning. Graphical output is currently not supported on Windows 10 (but will probably be available in the future). Therefore, working on Windows 11 is recommended. The installations on Windows relies on WSL 2, i.e. although working with Windows, the code is compiled and executed in Linux.","title":"Installation of Ikarus"},{"location":"download/#installation-on-windows-using-docker-container","text":"Install WSL: Open the PowerShell as an admin and execute the following commands. Reboot afterwards, if requested. wsl --install wsl --set-default-version 2 #(Is not needed for Windows 11) Download and install Docker for Windows . During the installation, select the option \"Install requred Windows components for WSL 2\" Install debian from WindowsAppStore Open the debian app Give yourself a username and password Close the debian app Open the PowerShell and execute: wsl --list --all Debian should appear as one of the available Linux distributions. In the PowerShell execute: wsl --setdefault Debian Try to start Docker. If it works, continue with the next step. If a message occurs that you are not allowed to use docker because you are not in the docker user group, follow these instructions . In short: Open Computerverwaltung as admin Go to Lokale Benutzer und Gruppen and find docker-users Add your Account (or a group of which you are a member) to the group. Restart your computer In Docker, go to Settings \u2192 General and select autostart for docker (otherwise you have to start it manually each time you want to work with Ikarus). In the Docker settings, select that Docker uses your WSL2 distribution Debian as shown in the picture. In cases docker says that you don't have a WSL 2 distribution, go to the PowerShell and execute wsl --set-default-version 2 #(just to be sure that you didn't forgot this at the beginning) wsl --set-version Debian 2 #(Converts debian to version 2) You should now be able to change the docker settings according to the picture above. Open the PowerShell and execute: docker pull rath3t/ikarus-debian-bookworm:latest Download and install CLion . You need a version >=2022.1. In CLion, go to File and Settings and apply the following settings for the toolchain: Edit the Container settings and paste the following command into Run options : -e DISPLAY=:0 -v \\\\wsl$\\debian\\mnt\\wslg\\.X11-unix:/tmp/.X11-unix -v \\\\wsl$\\debian\\mnt\\wslg:/mnt/wslg --cap-add=SYS_PTRACE Clone Ikarus","title":"Installation on Windows using Docker Container"},{"location":"download/#clone-ikarus","text":"Clone the Ikarus repository as you do it with any other repository (e.g. using GitKraken) ToDo: Describe here how to access it from Github.com Open the CMake tab CMake in the CLion footer: Click on Reload CMake project (refresh symbol) CMake now detects all required sources automatically. The output should look similar to the screenshot below","title":"Clone Ikarus"},{"location":"download/#installation-on-windows-using-wsl","text":"This installation procedure is not recommended The installation using Docker described above has several advantages and should be the standard. This section will be removed in the future Install WSL: Open the PowerShell as an admin and execute the following commands. Reboot afterwards, if requested. wsl --install wsl --set-default-version 2 #(Is not needed for Windows 11) Install debian from .tar file OR alternatively (3) wsl --import debian <install location> debian_bookworm.tar Install debian manually Install from WindowsAppStore Open the debian app Give yourself a username and password Execute in debian sudo sed -i 's/bullseye/bookworm/g' /etc/apt/sources.list Execute the following list of commands in debian sudo apt update && \\ sudo apt full-upgrade -y && \\ sudo apt -y install lsb-release && \\ sudo apt -y install build-essential \\ libssl-dev \\ git \\ wget \\ apt-utils \\ software-properties-common \\ gfortran \\ gcc-11 \\ g++-11 \\ gcovr \\ clang \\ libmetis-dev \\ clang-tidy \\ libclang-13-dev \\ clang-format-13 \\ libc++-13-dev \\ libc++abi-13-dev \\ llvm-13-dev \\ liblapack-dev \\ libopenblas-dev \\ libsuitesparse-dev \\ libdune-common-dev \\ libdune-geometry-dev \\ libdune-grid-dev \\ libdune-functions-dev \\ libdune-typetree-dev \\ libdune-localfunctions-dev \\ libdune-uggrid-dev \\ libdune-grid-glue-dev \\ libdune-istl-dev \\ libspdlog-dev \\ libbenchmark-dev \\ libgtest-dev \\ gnuplot \\ python3 \\ pip \\ clang-format-12 \\ gnuplot-x11 \\ curl \\ cppcheck && \\ sudo apt-get install libayatana-appindicator3-1 -y && \\ sudo apt-get -y -f install && \\ sudo apt install libasound2 xvfb -y && \\ wget https://github.com/jgraph/drawio-desktop/releases/download/v16.5.1/drawio-amd64-16.5.1.deb && \\ sudo dpkg -i drawio-amd64-16.5.1.deb && \\ pip install cmakelang == 0 .6.13 pyyaml && \\ pip install mkdocs && \\ pip install mkdocs-material && \\ pip install mkdocs-macros-plugin && \\ pip install mkdocs-drawio-exporter && \\ && \\ sudo cp /usr/bin/clang-format-12 /usr/bin/clang-format && \\ cd /usr/local/bin && \\ sudo ln -s $HOME /.local/bin/cmake-format cmake-format && \\ sudo ln -s $HOME /.local/bin/mkdocs mkdocs && \\ cd ~ && \\ mkdir -p iwyu && \\ cd iwyu && \\ git clone https://github.com/include-what-you-use/include-what-you-use.git && \\ cd include-what-you-use && \\ git checkout clang_13 && \\ cd .. && \\ mkdir -p build && cd build && \\ cmake -G \"Unix Makefiles\" -DIWYU_LLVM_ROOT_PATH = /usr/lib/llvm-13 ../include-what-you-use && \\ make && \\ sudo make install && \\ cd /usr/src/googletest && \\ cmake . && \\ sudo cmake --build . --target install && \\ cd ~ && \\ git clone https://gitlab.com/libeigen/eigen.git && \\ cd eigen && \\ git checkout 3 .4 && \\ mkdir build && \\ cd build && \\ cmake ../ && \\ sudo make install && \\ cd ~ && \\ rm -rf eigen && \\ git clone https://github.com/alandefreitas/matplotplusplus.git && \\ cd matplotplusplus && \\ mkdir -p build && \\ cd build && \\ cmake .. -DCMAKE_BUILD_TYPE = Release -DBUILD_EXAMPLES = OFF -DBUILD_TESTS = OFF && \\ cmake --build . --parallel 4 --config Release && \\ sudo cmake --install . && \\ cd ~ && \\ rm -rf matplotplusplus && \\ git clone https://github.com/autodiff/autodiff && \\ cd autodiff/ && \\ mkdir .build && \\ cd .build/ && \\ cmake .. -DAUTODIFF_BUILD_PYTHON = 0 -DAUTODIFF_BUILD_EXAMPLES = 0 -DAUTODIFF_BUILD_DOCS = 0 -DAUTODIFF_BUILD_TESTS = 0 && \\ sudo cmake --build . --target install && \\ cd ../.. && \\ mkdir -p dune && \\ cd dune && \\ git clone https://gitlab.dune-project.org/extensions/dune-alugrid.git && \\ git clone https://gitlab.dune-project.org/extensions/dune-foamgrid.git && \\ dunecontrol git checkout releases/2.8 && \\ git clone https://github.com/rath3t/dune-iga.git && \\ dunecontrol cmake \"-DCMAKE_BUILD_TYPE=Release\" && \\ dunecontrol make && \\ sudo dunecontrol make install && \\ cd .. && \\ rm -rf dune && \\ sudo apt-get auto-remove -y && \\ sudo apt-get clean wget https://raw.githubusercontent.com/JetBrains/clion-wsl/master/ubuntu_setup_env.sh && bash ubuntu_setup_env.sh In Clion, go to File and Settings and apply the following settings for the toolchain: Build, Execution, Deployment \u2192 Toolchains: Add with the + -sign a WSL configuration Make sure it is used as defaultm i.e. it has to be the first item in the list. Move it up with the arrow buttons otherwise.","title":"Installation on Windows using WSL"},{"location":"openTask/","text":"Open tasks \u00b6 Thanks for your interest in contributing to this code base. If your are interested the following task are vacant. Local functions \u00b6 Implementing a unit normal field function 1 and its derivatives w.r.t. its coefficients \\( \\boldsymbol{x}_i \\) \\[ \\boldsymbol{n} = \\frac{\\boldsymbol{a}_1 \\times \\boldsymbol{a}_2}{||\\boldsymbol{a}_1 \\times \\boldsymbol{a}_2||}, \\quad \\text{with } \\boldsymbol{a}_{\\alpha} = \\sum_{i=1}^n N^i_{,\\alpha}(\\boldsymbol{\\xi}) \\boldsymbol{x}_i \\] To implement these see link . Support second derivatives Add \\( \\operatorname{div} \\) and \\( \\operatorname{curl} \\) wrapper Controlroutines \u00b6 Arclength method Dynamics (Explicit/ implicit time stepping) Controlroutines addons \u00b6 Extended systems Inhomogeneous dirichlet boundary conditions wrapper class Finite element helper \u00b6 Implement default implemented mass matrix Finite elements \u00b6 Nonlinear Reissner-Mindlin shell 2 Kirchhoff-Love shell 3D-Beam Implement forces and stiffness matrix of NonLinearElasticityFE Local Basis \u00b6 Support second derivatives Addons \u00b6 Add Python binding pybind11 Add Muesli Code style For details on our code style we refer to Link . This is usually needed for a Kirchhoff-Love shell implementation, see 3 . \u21a9 Alexander M\u00fcller and Manfred Bischoff. A consistent finite element formulation of the geometrically non-linear reissner-mindlin shell model. Archives of Computational Methods in Engineering , pages 1\u201347, 2022. doi:10.1007/s11831-021-09702-7 . \u21a9 J. Kiendl, K.-U. Bletzinger, J. Linhard, and R. W\u00fcchner. Isogeometric shell analysis with kirchhoff\u2013love elements. Computer Methods in Applied Mechanics and Engineering , 198(49):3902\u20133914, 2009. doi:10.1016/j.cma.2009.08.013 . \u21a9","title":"Open Tasks"},{"location":"openTask/#open-tasks","text":"Thanks for your interest in contributing to this code base. If your are interested the following task are vacant.","title":"Open tasks"},{"location":"openTask/#local-functions","text":"Implementing a unit normal field function 1 and its derivatives w.r.t. its coefficients \\( \\boldsymbol{x}_i \\) \\[ \\boldsymbol{n} = \\frac{\\boldsymbol{a}_1 \\times \\boldsymbol{a}_2}{||\\boldsymbol{a}_1 \\times \\boldsymbol{a}_2||}, \\quad \\text{with } \\boldsymbol{a}_{\\alpha} = \\sum_{i=1}^n N^i_{,\\alpha}(\\boldsymbol{\\xi}) \\boldsymbol{x}_i \\] To implement these see link . Support second derivatives Add \\( \\operatorname{div} \\) and \\( \\operatorname{curl} \\) wrapper","title":"Local functions"},{"location":"openTask/#controlroutines","text":"Arclength method Dynamics (Explicit/ implicit time stepping)","title":"Controlroutines"},{"location":"openTask/#controlroutines-addons","text":"Extended systems Inhomogeneous dirichlet boundary conditions wrapper class","title":"Controlroutines addons"},{"location":"openTask/#finite-element-helper","text":"Implement default implemented mass matrix","title":"Finite element helper"},{"location":"openTask/#finite-elements","text":"Nonlinear Reissner-Mindlin shell 2 Kirchhoff-Love shell 3D-Beam Implement forces and stiffness matrix of NonLinearElasticityFE","title":"Finite elements"},{"location":"openTask/#local-basis","text":"Support second derivatives","title":"Local Basis"},{"location":"openTask/#addons","text":"Add Python binding pybind11 Add Muesli Code style For details on our code style we refer to Link . This is usually needed for a Kirchhoff-Love shell implementation, see 3 . \u21a9 Alexander M\u00fcller and Manfred Bischoff. A consistent finite element formulation of the geometrically non-linear reissner-mindlin shell model. Archives of Computational Methods in Engineering , pages 1\u201347, 2022. doi:10.1007/s11831-021-09702-7 . \u21a9 J. Kiendl, K.-U. Bletzinger, J. Linhard, and R. W\u00fcchner. Isogeometric shell analysis with kirchhoff\u2013love elements. Computer Methods in Applied Mechanics and Engineering , 198(49):3902\u20133914, 2009. doi:10.1016/j.cma.2009.08.013 . \u21a9","title":"Addons"},{"location":"01_theory/assembler/","text":"Assembler \u00b6 The purpose of an assembler is to assemble global quantities (global stiffness matrix, global force vector, global energy, ...) by looping over finite elements and composing the corresponding local structures to a global structure. This page describes the available assemblers and how they can be used. Each of the assemblers is constructed as follows: AssemblerName ( const Basis & basis , const FEContainer & fes , const std :: vector < bool >& dirichFlags ) basis is the basis that was used to construct the finite elements. ToDo add comment about FLAT. fes is a container that contains all the finite elements that should be assembled dirichFlags is of type std :: vector < bool > . dirichFlags [ i ] = true means that degree of freedom i is fixed. The corresponding row / column / entry will be eliminated when you ask for reduced matrix / vector. FlatAssemblerBase \u00b6 The FlatAssemblerBase is the basis for all assemblers currently available. All other Assemblers inherit from this assembler, i.e. they have the functions listed below as well: size_t size () // (1) size_t reducedSize () // (2) auto & finiteElements () const // (3) Eigen :: VectorXd createFullVector ( const Eigen :: VectorXd & reducedVector ) // (4) size_t constraintsBelow ( size_t i ) // (5) bool isConstrained ( size_t i ) // (6) size_t estimateOfConnectivity () // (7) Returns the number of degress of freedom. Returns the number of degrees of freeedom, which are not constrained by a dirichlet boundary condition. Returns a reference to the finite element container that you gave to the assembler when constructing it. Gets a reduced vector and returns a full vector. Entries corresponding to fixed dofs are set to 0. Values of the other entries are obtained from the reduced vector. Tells you how many of the degrees of freedom {0,1,...i-1} are fixed. Tells you if degree of freedom i is fixed Returns 8x the number of grid elements, which is an estimate for the connectivity. It can be used to allocate vectors. ScalarAssembler \u00b6 It has the capabilities of FlatAssemblerBase plus one additional function: double & getScalar ( const RequirementType & fErequirements ) This assembler can be used when you are only interested in a scalar quantity and assembling of matrices or vectors is not relevant for you. The available requirements are explained on the FE requirements page . dirichletFlags is not used in this assembler. It assembles the reqested scalar quantity. A call to this function could look as follows: ScalarAssembler myAssembler (...) // (1) // other code const auto & K = myAssembler . getScalar ( energy ) // (2) This line represents the construction of the SparseFlatAssembler as explained above. To learn what alternatives for energy are available and how this works, read the FE requirements page . VectorFlatAssembler \u00b6 It offers the functions of ScalarAssembler plus additionally Eigen :: VectorXd & getVector ( const RequirementType & fErequirements ) Eigen :: VectorXd & getReducedVector ( const RequirementType & fErequirements ) As the name suggests, you can either get the full vector or the reduced vector where boundary conditions are considered. They work the same way as the scalar assembling functions of ScalarAssembler . The available requirements are explained on the FE requirements page . SparseFlatAssembler \u00b6 It offers the functions of VectorFlatAssembler plus additionally Eigen :: SparseMatrix < double > & getMatrix ( const RequirementType & fErequirements ) Eigen :: SparseMatrix < double > & getReducedMatrix ( const RequirementType & fErequirements ) A sparse matrix is returned. They work the same way as the vector assembling functions of VectorFlatAssembler . The available requirements are explained on the FE requirements page . DenseFlatAssembler \u00b6 The only difference between the SparseFlatAssembler and the DenseFlatAssembler is that the DenseFlatAssembler returns a dense matrix. Eigen :: MatrixXd & getMatrix ( const RequirementType & fErequirements ) Eigen :: MatrixXd & getReducedMatrix ( const RequirementType & fErequirements )","title":"Assembler"},{"location":"01_theory/assembler/#assembler","text":"The purpose of an assembler is to assemble global quantities (global stiffness matrix, global force vector, global energy, ...) by looping over finite elements and composing the corresponding local structures to a global structure. This page describes the available assemblers and how they can be used. Each of the assemblers is constructed as follows: AssemblerName ( const Basis & basis , const FEContainer & fes , const std :: vector < bool >& dirichFlags ) basis is the basis that was used to construct the finite elements. ToDo add comment about FLAT. fes is a container that contains all the finite elements that should be assembled dirichFlags is of type std :: vector < bool > . dirichFlags [ i ] = true means that degree of freedom i is fixed. The corresponding row / column / entry will be eliminated when you ask for reduced matrix / vector.","title":"Assembler"},{"location":"01_theory/assembler/#flatassemblerbase","text":"The FlatAssemblerBase is the basis for all assemblers currently available. All other Assemblers inherit from this assembler, i.e. they have the functions listed below as well: size_t size () // (1) size_t reducedSize () // (2) auto & finiteElements () const // (3) Eigen :: VectorXd createFullVector ( const Eigen :: VectorXd & reducedVector ) // (4) size_t constraintsBelow ( size_t i ) // (5) bool isConstrained ( size_t i ) // (6) size_t estimateOfConnectivity () // (7) Returns the number of degress of freedom. Returns the number of degrees of freeedom, which are not constrained by a dirichlet boundary condition. Returns a reference to the finite element container that you gave to the assembler when constructing it. Gets a reduced vector and returns a full vector. Entries corresponding to fixed dofs are set to 0. Values of the other entries are obtained from the reduced vector. Tells you how many of the degrees of freedom {0,1,...i-1} are fixed. Tells you if degree of freedom i is fixed Returns 8x the number of grid elements, which is an estimate for the connectivity. It can be used to allocate vectors.","title":"FlatAssemblerBase"},{"location":"01_theory/assembler/#scalarassembler","text":"It has the capabilities of FlatAssemblerBase plus one additional function: double & getScalar ( const RequirementType & fErequirements ) This assembler can be used when you are only interested in a scalar quantity and assembling of matrices or vectors is not relevant for you. The available requirements are explained on the FE requirements page . dirichletFlags is not used in this assembler. It assembles the reqested scalar quantity. A call to this function could look as follows: ScalarAssembler myAssembler (...) // (1) // other code const auto & K = myAssembler . getScalar ( energy ) // (2) This line represents the construction of the SparseFlatAssembler as explained above. To learn what alternatives for energy are available and how this works, read the FE requirements page .","title":"ScalarAssembler"},{"location":"01_theory/assembler/#vectorflatassembler","text":"It offers the functions of ScalarAssembler plus additionally Eigen :: VectorXd & getVector ( const RequirementType & fErequirements ) Eigen :: VectorXd & getReducedVector ( const RequirementType & fErequirements ) As the name suggests, you can either get the full vector or the reduced vector where boundary conditions are considered. They work the same way as the scalar assembling functions of ScalarAssembler . The available requirements are explained on the FE requirements page .","title":"VectorFlatAssembler"},{"location":"01_theory/assembler/#sparseflatassembler","text":"It offers the functions of VectorFlatAssembler plus additionally Eigen :: SparseMatrix < double > & getMatrix ( const RequirementType & fErequirements ) Eigen :: SparseMatrix < double > & getReducedMatrix ( const RequirementType & fErequirements ) A sparse matrix is returned. They work the same way as the vector assembling functions of VectorFlatAssembler . The available requirements are explained on the FE requirements page .","title":"SparseFlatAssembler"},{"location":"01_theory/assembler/#denseflatassembler","text":"The only difference between the SparseFlatAssembler and the DenseFlatAssembler is that the DenseFlatAssembler returns a dense matrix. Eigen :: MatrixXd & getMatrix ( const RequirementType & fErequirements ) Eigen :: MatrixXd & getReducedMatrix ( const RequirementType & fErequirements )","title":"DenseFlatAssembler"},{"location":"01_theory/controlRoutines/","text":"Control routines \u00b6 Load control \u00b6 A load control object is constructed as follows: auto lc = Ikarus :: LoadControl ( nonlinearSolver , numLoadSteps , { loadFactorStartValue , loadFactorEndValue }); nonlinearSolver is a nonlinear Solver, e.g. Newton-Raphson. numLoadSteps is the number of load steps, loadFactorStartValue is the value of the load factor at the beginning of the simulation (usually 0) and loadFactorEndValue is the load factor at the end of the simulation. The load control is started with the run() method, i.e. in the example above: lc . run (); Obtaining infos from control routines \u00b6 The load control is an observable object, i.e. you can subscribe to the messages of the load control. Read this page to learn more about the implementation of observer pattern in Ikarus. The following messages are available: enum class ControlMessages { BEGIN , CONTROL_STARTED , CONTROL_ENDED , STEP_STARTED , STEP_ENDED , SOLUTION_CHANGED , END };","title":"Control routines"},{"location":"01_theory/controlRoutines/#control-routines","text":"","title":"Control routines"},{"location":"01_theory/controlRoutines/#load-control","text":"A load control object is constructed as follows: auto lc = Ikarus :: LoadControl ( nonlinearSolver , numLoadSteps , { loadFactorStartValue , loadFactorEndValue }); nonlinearSolver is a nonlinear Solver, e.g. Newton-Raphson. numLoadSteps is the number of load steps, loadFactorStartValue is the value of the load factor at the beginning of the simulation (usually 0) and loadFactorEndValue is the load factor at the end of the simulation. The load control is started with the run() method, i.e. in the example above: lc . run ();","title":"Load control"},{"location":"01_theory/controlRoutines/#obtaining-infos-from-control-routines","text":"The load control is an observable object, i.e. you can subscribe to the messages of the load control. Read this page to learn more about the implementation of observer pattern in Ikarus. The following messages are available: enum class ControlMessages { BEGIN , CONTROL_STARTED , CONTROL_ENDED , STEP_STARTED , STEP_ENDED , SOLUTION_CHANGED , END };","title":"Obtaining infos from control routines"},{"location":"01_theory/feRequirements/","text":"FE requirements \u00b6 Finite element requirements are a simply way to communicate your needs and expectations from a finite element. FE requirements are used to pass information from assemblers to finite elements. Construction \u00b6 Usually the construction is as follows. 1 2 3 4 5 6 FErequirements req = FErequirementsBuilder () . insertGlobalSolution ( FESolutions :: displacement , d ) . insertParameter ( FEParameter :: loadfactor , lambda ) . addAffordance ( MatrixAffordances :: stiffness ) . build (); MatrixType A = sparseFlatAssembler . getReducedMatrix ( req ); As you can see to construct requirements we used the builder pattern 1 . Thus to construct FErequirements you create a FErequirementsBuilder . You can then chain your requirements together. You can insert solution from your finite element solution algorithm as in line 2. There, the type of the soultion is passed with the enum type FESolutions::displacement with the vector d . This stores a reference to the vector. Additionally, if you have some parameters you want to pass you can call the method insertParameter as in line 3, where similar as for the global solutions a enum FEParameter::loadfactor is passed to indicate the meaning of the parameter and after this the value is passed. Finally there is the method addAffordance which is used to indicate your request what you want from the finite element. Thus, there are scalar, vector and matrix affordances. The method build() constructs at the end the concrete object. Currently, the following feSolutions, fe Parameter and affordances are defined: namespace Ikarus { // clang-format off enum class ScalarAffordances { noAffordance , mechanicalPotentialEnergy , microMagneticPotentialEnergy }; enum class VectorAffordances { noAffordance , forces , microMagneticForces }; enum class MatrixAffordances { noAffordance , stiffness , materialstiffness , geometricstiffness , stiffnessdiffBucklingVector , microMagneticHessian , mass }; enum class FEParameter { noParameter , loadfactor , time }; enum class FESolutions { noSolution , displacement , velocity , Usage \u00b6 Inside the finite element the information can than be convieniently extracted: 1 2 3 4 const auto & d = req . getSolution ( FESolutions :: displacement ); const auto & lambda = req . getParameter ( FEParameter :: loadfactor ); if ( req . hasAffordance ( stiffness )) ... and with this you can develop your local finite element. Affordance It is good style to indicate that you can not fulfill an affordance by throwing an appropriate exception! FE result requirements \u00b6 Additionally, to the upper finite element requirements there are result requirements. They have the same methods as finite element requirements but add additional ones. They are used for the calculateAt method of finite elements . They are a way to communicate the requested results to the finite elements. Construction \u00b6 Similar to above the construction is as follow: 1 2 3 4 ResultRequirements resultRequirements = Ikarus :: ResultRequirementsBuilder () . insertGlobalSolution ( FESolutions :: displacement , d ) . insertParameter ( FEParameter :: loadfactor , lambda ) . addResultRequest ( ResultType :: cauchyStress ,, ResultType :: director ). build (); The current supported results are magnetizationAndVectorPotential }; enum class ResultType { noType , magnetization , gradientNormOfMagnetization , vectorPotential , divergenceOfVectorPotential , Usage \u00b6 To extract the needed information result requirements have the same interface as finite element requirements. But they allow to query information whic hresults should be calculated. if ( req . isResultRequested ( ResultType :: cauchyStress )) { ... } if ( req . isResultRequested ( ResultType :: BField )) { ... } if ( req . isResultRequested ( ResultType :: director )) { ... } Erich Gamma, Richard Helm, Ralph Johnson, Ralph E Johnson, John Vlissides, and others. Design patterns: elements of reusable object-oriented software . Pearson Deutschland GmbH, 1995. \u21a9","title":"FE requirements"},{"location":"01_theory/feRequirements/#fe-requirements","text":"Finite element requirements are a simply way to communicate your needs and expectations from a finite element. FE requirements are used to pass information from assemblers to finite elements.","title":"FE requirements"},{"location":"01_theory/feRequirements/#construction","text":"Usually the construction is as follows. 1 2 3 4 5 6 FErequirements req = FErequirementsBuilder () . insertGlobalSolution ( FESolutions :: displacement , d ) . insertParameter ( FEParameter :: loadfactor , lambda ) . addAffordance ( MatrixAffordances :: stiffness ) . build (); MatrixType A = sparseFlatAssembler . getReducedMatrix ( req ); As you can see to construct requirements we used the builder pattern 1 . Thus to construct FErequirements you create a FErequirementsBuilder . You can then chain your requirements together. You can insert solution from your finite element solution algorithm as in line 2. There, the type of the soultion is passed with the enum type FESolutions::displacement with the vector d . This stores a reference to the vector. Additionally, if you have some parameters you want to pass you can call the method insertParameter as in line 3, where similar as for the global solutions a enum FEParameter::loadfactor is passed to indicate the meaning of the parameter and after this the value is passed. Finally there is the method addAffordance which is used to indicate your request what you want from the finite element. Thus, there are scalar, vector and matrix affordances. The method build() constructs at the end the concrete object. Currently, the following feSolutions, fe Parameter and affordances are defined: namespace Ikarus { // clang-format off enum class ScalarAffordances { noAffordance , mechanicalPotentialEnergy , microMagneticPotentialEnergy }; enum class VectorAffordances { noAffordance , forces , microMagneticForces }; enum class MatrixAffordances { noAffordance , stiffness , materialstiffness , geometricstiffness , stiffnessdiffBucklingVector , microMagneticHessian , mass }; enum class FEParameter { noParameter , loadfactor , time }; enum class FESolutions { noSolution , displacement , velocity ,","title":"Construction"},{"location":"01_theory/feRequirements/#usage","text":"Inside the finite element the information can than be convieniently extracted: 1 2 3 4 const auto & d = req . getSolution ( FESolutions :: displacement ); const auto & lambda = req . getParameter ( FEParameter :: loadfactor ); if ( req . hasAffordance ( stiffness )) ... and with this you can develop your local finite element. Affordance It is good style to indicate that you can not fulfill an affordance by throwing an appropriate exception!","title":"Usage"},{"location":"01_theory/feRequirements/#fe-result-requirements","text":"Additionally, to the upper finite element requirements there are result requirements. They have the same methods as finite element requirements but add additional ones. They are used for the calculateAt method of finite elements . They are a way to communicate the requested results to the finite elements.","title":"FE result requirements"},{"location":"01_theory/feRequirements/#construction_1","text":"Similar to above the construction is as follow: 1 2 3 4 ResultRequirements resultRequirements = Ikarus :: ResultRequirementsBuilder () . insertGlobalSolution ( FESolutions :: displacement , d ) . insertParameter ( FEParameter :: loadfactor , lambda ) . addResultRequest ( ResultType :: cauchyStress ,, ResultType :: director ). build (); The current supported results are magnetizationAndVectorPotential }; enum class ResultType { noType , magnetization , gradientNormOfMagnetization , vectorPotential , divergenceOfVectorPotential ,","title":"Construction"},{"location":"01_theory/feRequirements/#usage_1","text":"To extract the needed information result requirements have the same interface as finite element requirements. But they allow to query information whic hresults should be calculated. if ( req . isResultRequested ( ResultType :: cauchyStress )) { ... } if ( req . isResultRequested ( ResultType :: BField )) { ... } if ( req . isResultRequested ( ResultType :: director )) { ... } Erich Gamma, Richard Helm, Ralph Johnson, Ralph E Johnson, John Vlissides, and others. Design patterns: elements of reusable object-oriented software . Pearson Deutschland GmbH, 1995. \u21a9","title":"Usage"},{"location":"01_theory/finiteElements/","text":"Finite elements \u00b6 Several disciplines associate to finite elements different meanings. In Ikarus finite elements have two different tasks. The first one is to provide the evaluation of scalars, vectors and matrices. These are associated to an algebraic representation of discrete energies, weak forms or bilinear forms These algebraic objects are usually constructed using some combination of local function and parameters steeming from the underlying physical problem, e.g. load factor, Young's modulus or viscocity. The second task of finite elements is to evaluate derived results in the element parameter space. E.g. stresses or geometric quantities. This boils down to the following interface. Interface \u00b6 Local functions provide the following interface ScalarType evaluateScalar ( const FErequirements & req ); void evaluateVector ( const FErequirements & req , VectorType & b ); void evaluateMatrix ( const FErequirements & req , MatrixType & A ); void calculateLocalSystem ( const FErequirements & req , MatrixType & A , VectorType & b ); void calculateAt ( const Resultrequirements & req , const Eigen :: Vector < double , Traits :: mydim >& local , ResultTypeMap < ScalarType >& result ); void globalIndices ( std :: vector < GlobalIndex >& globalIndices ); To discuss these methods first finite element requirements and result requirements should be learned, see fe requirements . The first four methods receive an object of type FErequirements . This object is responsable for passing different inforamtion needed for the local evaluation of the local linear algebra objects. The first method evaluateScalar simply returns by values since usually this is cheap to return a double . The other methods evaluateVector , evaluateMatrix and calculateLocalSystem receive one or two output argument where the result should be written. This interface is needed to circumvent the dynamic memory allocation, if these methods would return by value. The method calculateAt is responable to evaluate several results and it receives a ResultRequirements ojbect which contains information which results should be evaluated. These results are stored inside the output argument result which is of type ResultTypeMap . Additionally there is the argument 'local' which stores the coordinates where inside the element coordinates the result should be evaluated. Inside a typical calculateAt method the usage is typename ResultTypeMap < double >:: ResultArray res ; if ( req . isResultRequested ( ResultType :: gradientNormOfMagnetization )) { res . resize ( 1 , 1 ); res ( 0 , 0 ) = ...; result . insertOrAssignResult ( ResultType :: gradientNormOfMagnetization , res ); } if ( req . isResultRequested ( ResultType :: BField )) { res . setZero ( 3 , 1 ); res = ...; result . insertOrAssignResult ( ResultType :: BField , res ); } if ( req . isResultRequested ( ResultType :: cauchyStress )) { res . setZero ( 3 , 3 ); res = ...; result . insertOrAssignResult ( ResultType :: cauchyStress , res ); } ResultTypeMap<double>::ResultArray ResultTypeMap < double >:: ResultArray is an object of type Eigen :: Matrix < double , Eigen :: Dynamic , Eigen :: Dynamic , 0 , 3 , 3 > . Thus, the maximum result size is limited to a 3x3 matrix. This is used to circumvent dynamic memory allocations. The last method is globalIndices . It is used to message the global indices of this finite element steming in the output parameter globalIndices . This information should stem from a basis object. See existing implementations for details.","title":"Finite Elements"},{"location":"01_theory/finiteElements/#finite-elements","text":"Several disciplines associate to finite elements different meanings. In Ikarus finite elements have two different tasks. The first one is to provide the evaluation of scalars, vectors and matrices. These are associated to an algebraic representation of discrete energies, weak forms or bilinear forms These algebraic objects are usually constructed using some combination of local function and parameters steeming from the underlying physical problem, e.g. load factor, Young's modulus or viscocity. The second task of finite elements is to evaluate derived results in the element parameter space. E.g. stresses or geometric quantities. This boils down to the following interface.","title":"Finite elements"},{"location":"01_theory/finiteElements/#interface","text":"Local functions provide the following interface ScalarType evaluateScalar ( const FErequirements & req ); void evaluateVector ( const FErequirements & req , VectorType & b ); void evaluateMatrix ( const FErequirements & req , MatrixType & A ); void calculateLocalSystem ( const FErequirements & req , MatrixType & A , VectorType & b ); void calculateAt ( const Resultrequirements & req , const Eigen :: Vector < double , Traits :: mydim >& local , ResultTypeMap < ScalarType >& result ); void globalIndices ( std :: vector < GlobalIndex >& globalIndices ); To discuss these methods first finite element requirements and result requirements should be learned, see fe requirements . The first four methods receive an object of type FErequirements . This object is responsable for passing different inforamtion needed for the local evaluation of the local linear algebra objects. The first method evaluateScalar simply returns by values since usually this is cheap to return a double . The other methods evaluateVector , evaluateMatrix and calculateLocalSystem receive one or two output argument where the result should be written. This interface is needed to circumvent the dynamic memory allocation, if these methods would return by value. The method calculateAt is responable to evaluate several results and it receives a ResultRequirements ojbect which contains information which results should be evaluated. These results are stored inside the output argument result which is of type ResultTypeMap . Additionally there is the argument 'local' which stores the coordinates where inside the element coordinates the result should be evaluated. Inside a typical calculateAt method the usage is typename ResultTypeMap < double >:: ResultArray res ; if ( req . isResultRequested ( ResultType :: gradientNormOfMagnetization )) { res . resize ( 1 , 1 ); res ( 0 , 0 ) = ...; result . insertOrAssignResult ( ResultType :: gradientNormOfMagnetization , res ); } if ( req . isResultRequested ( ResultType :: BField )) { res . setZero ( 3 , 1 ); res = ...; result . insertOrAssignResult ( ResultType :: BField , res ); } if ( req . isResultRequested ( ResultType :: cauchyStress )) { res . setZero ( 3 , 3 ); res = ...; result . insertOrAssignResult ( ResultType :: cauchyStress , res ); } ResultTypeMap<double>::ResultArray ResultTypeMap < double >:: ResultArray is an object of type Eigen :: Matrix < double , Eigen :: Dynamic , Eigen :: Dynamic , 0 , 3 , 3 > . Thus, the maximum result size is limited to a 3x3 matrix. This is used to circumvent dynamic memory allocations. The last method is globalIndices . It is used to message the global indices of this finite element steming in the output parameter globalIndices . This information should stem from a basis object. See existing implementations for details.","title":"Interface"},{"location":"01_theory/geometry/","text":"Geometry \u00b6 For the notion of geometry of the grid entities we rely on the definitions of dune. For details, see 1 Chapter 5.3. Oliver Sander. DUNE\u2014The Distributed and Unified Numerics Environment . Volume 140. Springer Nature, 2020. URL: https://link.springer.com/book/10.1007/978-3-030-59702-3 . \u21a9","title":"Geometry"},{"location":"01_theory/geometry/#geometry","text":"For the notion of geometry of the grid entities we rely on the definitions of dune. For details, see 1 Chapter 5.3. Oliver Sander. DUNE\u2014The Distributed and Unified Numerics Environment . Volume 140. Springer Nature, 2020. URL: https://link.springer.com/book/10.1007/978-3-030-59702-3 . \u21a9","title":"Geometry"},{"location":"01_theory/globalBasis/","text":"Global basis \u00b6 In finite element simulations, we often talk about elements and meshes. What we commonly refer to as \"element\" consists of various aspects with different tasks, e.g. These elements always connected and disconnected in different ways. These connections depend on the underlying basis that is assumed for the solution fields. The basis functions have usually a local support. E.g. simple 1-D linear Lagrange basis span over two elements. The connection relation can be encoded in the common vertex node. If we assume higher order 2-D Lagrangian basis function this connection can be associated to a common edge. There are also ansatz function that only have support within one element. These function are sometimes called bubble-functions. In the context of discontinuous Galerkin methods the elements are not connected at all. As last example, if we consider B-Spline basis functions the association of the connection between elements to geometric entities such as edges, vertices fails. Nevertheless, all this connection information is needed to assemble the global systems matrices. However, the global basis needs to provide indices that encode this connectivity depending on the give finite element This is quite different for different basis. There exists not only one global base. We are relying here one the basis defined by dune. Thus they use the same interface. For details see 1 Chapter 10. Oliver Sander. DUNE\u2014The Distributed and Unified Numerics Environment . Volume 140. Springer Nature, 2020. URL: https://link.springer.com/book/10.1007/978-3-030-59702-3 . \u21a9","title":"Global basis"},{"location":"01_theory/globalBasis/#global-basis","text":"In finite element simulations, we often talk about elements and meshes. What we commonly refer to as \"element\" consists of various aspects with different tasks, e.g. These elements always connected and disconnected in different ways. These connections depend on the underlying basis that is assumed for the solution fields. The basis functions have usually a local support. E.g. simple 1-D linear Lagrange basis span over two elements. The connection relation can be encoded in the common vertex node. If we assume higher order 2-D Lagrangian basis function this connection can be associated to a common edge. There are also ansatz function that only have support within one element. These function are sometimes called bubble-functions. In the context of discontinuous Galerkin methods the elements are not connected at all. As last example, if we consider B-Spline basis functions the association of the connection between elements to geometric entities such as edges, vertices fails. Nevertheless, all this connection information is needed to assemble the global systems matrices. However, the global basis needs to provide indices that encode this connectivity depending on the give finite element This is quite different for different basis. There exists not only one global base. We are relying here one the basis defined by dune. Thus they use the same interface. For details see 1 Chapter 10. Oliver Sander. DUNE\u2014The Distributed and Unified Numerics Environment . Volume 140. Springer Nature, 2020. URL: https://link.springer.com/book/10.1007/978-3-030-59702-3 . \u21a9","title":"Global basis"},{"location":"01_theory/grid/","text":"Description of the grid \u00b6 In finite element simulations, we often talk about elements and meshes. What we commonly refer to as \"element\" consists of various aspects with different tasks, e.g. provide a unique identifier (element number) provide a description of the reference geometry (element shape in physical space, shape functions, etc.) provide quantities with physical meaning (mass matrix, stiffness matrix, internal force vector, etc.) ... In the code, there is not one single class which performs all these tasks. Different tasks are performed by different classes, which are described in the following. Especially, the description of the geometry is decoupled from the task to provide physical meaning. The following content is only about the description of the element geometry . Details on the implementation of physical quantities can be found here . For the notion of grids, grid entities and grid factories we rely on the definitions of dune. For details, see 1 Chapter 5. Available grid implementations \u00b6 All grids that satisfy the dune::grid interface can be used. For an overview of the available dune::grids, we refer to link . Additionally, there exists an iga grid dune-iga . Oliver Sander. DUNE\u2014The Distributed and Unified Numerics Environment . Volume 140. Springer Nature, 2020. URL: https://link.springer.com/book/10.1007/978-3-030-59702-3 . \u21a9","title":"Grid"},{"location":"01_theory/grid/#description-of-the-grid","text":"In finite element simulations, we often talk about elements and meshes. What we commonly refer to as \"element\" consists of various aspects with different tasks, e.g. provide a unique identifier (element number) provide a description of the reference geometry (element shape in physical space, shape functions, etc.) provide quantities with physical meaning (mass matrix, stiffness matrix, internal force vector, etc.) ... In the code, there is not one single class which performs all these tasks. Different tasks are performed by different classes, which are described in the following. Especially, the description of the geometry is decoupled from the task to provide physical meaning. The following content is only about the description of the element geometry . Details on the implementation of physical quantities can be found here . For the notion of grids, grid entities and grid factories we rely on the definitions of dune. For details, see 1 Chapter 5.","title":"Description of the grid"},{"location":"01_theory/grid/#available-grid-implementations","text":"All grids that satisfy the dune::grid interface can be used. For an overview of the available dune::grids, we refer to link . Additionally, there exists an iga grid dune-iga . Oliver Sander. DUNE\u2014The Distributed and Unified Numerics Environment . Volume 140. Springer Nature, 2020. URL: https://link.springer.com/book/10.1007/978-3-030-59702-3 . \u21a9","title":"Available grid implementations"},{"location":"01_theory/localBasis/","text":"Local Basis \u00b6 Each finite element does have some kind of local basis in terms of ansatz functions. These ansatz function need to be evaluated at the parameter domain of the finite element. Interface \u00b6 Local basis provide the following interface LocalBasis ( const DuneLocalBasis & p_basis ) // Constructor (1) void evaluateFunction ( const DomainType & local , Eigen :: VectorX < RangeFieldType >& N ); void evaluateJacobian ( const DomainType & local , Eigen :: Matrix < RangeFieldType , Eigen :: Dynamic , gridDim >& dN ); void evaluateFunctionAndJacobian ( const DomainType & local , Eigen :: VectorX < RangeFieldType >& N , Eigen :: Matrix < RangeFieldType , Eigen :: Dynamic , gridDim >& dN ); const Eigen :: VectorX < RangeFieldType >& evaluateFunction ( const unsigned int & integrationPointIndex ); const Eigen :: Matrix < RangeFieldType , Eigen :: Dynamic , gridDim >& evaluateJacobian ( const unsigned int & integrationPointIndex ); auto viewOverIntegrationPoints (); // (2) template < typename IntegrationRule , typename ... Ints > void bind ( IntegrationRule && p_rule , Derivatives < Ints ... >&& ints ); Using the concept Concepts::DuneLocalBasis the constructor only accepts local basis that satisfies this concept. This also allows a local basis which behave lik a local basis of dune in the spirit of duck-typing. This return a vector of structs of the integration point and its index. Therefore the syntax is usually for ( const auto & [ gpIndex , gp ] : localFunction . viewOverIntegrationPoints ()) {...} The first two function calls of evaluateFunction and evaluateJacobian can be used to calculate the function values \\( N(\\boldsymbol{\\xi}) \\) and the spatial derivatives \\( N_{,\\boldsymbol{\\xi}}(\\boldsymbol{\\xi}) \\) . The objects where this is stored you have to allocate yourself and have to pass as mutable reference. In contrast to this there exists two other methods that receive an integration point index. These methods return a const reference to the evaluated ansatz function values and derivatives. This functionality depends on an earlier call to bind(...) . This binds the local basis to one quadrature rule and caches the passed bindDerivatives(..) . If one calls evaluateFunction ( const unsigned int & integrationPointIndex ) before bind an error is thrown. Finally, to bind to an integration rule and cache the value and the ansatz function jacobian one would call: Usage with integration point index using integration point coordinates 1 2 3 4 5 6 7 const auto & rule = Dune :: QuadratureRules < double , Traits :: mydim >:: rule ( localView_ . element (). type (), order ); localBasis . bind ( rule , bindDerivatives ( 0 , 1 )); for ( const auto & [ gpIndex , gp ] : localBasis . viewOverIntegrationPoints ()) { const auto & N = localBasis . evaluateFunction ( gpIndex ); const auto & dN = localBasis . evaluateJacobian ( gpIndex ); } 1 2 3 4 5 6 7 8 9 const auto & rule = Dune :: QuadratureRules < double , Traits :: mydim >:: rule ( localView_ . element (). type (), order ); Eigen :: VectorXd N ; Eigen :: Matrix < double , Eigen :: Dynamic , gridDim > dN ; for ( auto & gp : rule ){ localFunction . evaluateFunction ( gp . position (), N ); localFunction . evaluateJacobian ( gp . position (), dN ); localFunction . evaluateFunctionAndJacobian ( gp . position (), N , dN ); // (1) } Alternative to the two lines above (Line 6 and 7)","title":"Local basis"},{"location":"01_theory/localBasis/#local-basis","text":"Each finite element does have some kind of local basis in terms of ansatz functions. These ansatz function need to be evaluated at the parameter domain of the finite element.","title":"Local Basis"},{"location":"01_theory/localBasis/#interface","text":"Local basis provide the following interface LocalBasis ( const DuneLocalBasis & p_basis ) // Constructor (1) void evaluateFunction ( const DomainType & local , Eigen :: VectorX < RangeFieldType >& N ); void evaluateJacobian ( const DomainType & local , Eigen :: Matrix < RangeFieldType , Eigen :: Dynamic , gridDim >& dN ); void evaluateFunctionAndJacobian ( const DomainType & local , Eigen :: VectorX < RangeFieldType >& N , Eigen :: Matrix < RangeFieldType , Eigen :: Dynamic , gridDim >& dN ); const Eigen :: VectorX < RangeFieldType >& evaluateFunction ( const unsigned int & integrationPointIndex ); const Eigen :: Matrix < RangeFieldType , Eigen :: Dynamic , gridDim >& evaluateJacobian ( const unsigned int & integrationPointIndex ); auto viewOverIntegrationPoints (); // (2) template < typename IntegrationRule , typename ... Ints > void bind ( IntegrationRule && p_rule , Derivatives < Ints ... >&& ints ); Using the concept Concepts::DuneLocalBasis the constructor only accepts local basis that satisfies this concept. This also allows a local basis which behave lik a local basis of dune in the spirit of duck-typing. This return a vector of structs of the integration point and its index. Therefore the syntax is usually for ( const auto & [ gpIndex , gp ] : localFunction . viewOverIntegrationPoints ()) {...} The first two function calls of evaluateFunction and evaluateJacobian can be used to calculate the function values \\( N(\\boldsymbol{\\xi}) \\) and the spatial derivatives \\( N_{,\\boldsymbol{\\xi}}(\\boldsymbol{\\xi}) \\) . The objects where this is stored you have to allocate yourself and have to pass as mutable reference. In contrast to this there exists two other methods that receive an integration point index. These methods return a const reference to the evaluated ansatz function values and derivatives. This functionality depends on an earlier call to bind(...) . This binds the local basis to one quadrature rule and caches the passed bindDerivatives(..) . If one calls evaluateFunction ( const unsigned int & integrationPointIndex ) before bind an error is thrown. Finally, to bind to an integration rule and cache the value and the ansatz function jacobian one would call: Usage with integration point index using integration point coordinates 1 2 3 4 5 6 7 const auto & rule = Dune :: QuadratureRules < double , Traits :: mydim >:: rule ( localView_ . element (). type (), order ); localBasis . bind ( rule , bindDerivatives ( 0 , 1 )); for ( const auto & [ gpIndex , gp ] : localBasis . viewOverIntegrationPoints ()) { const auto & N = localBasis . evaluateFunction ( gpIndex ); const auto & dN = localBasis . evaluateJacobian ( gpIndex ); } 1 2 3 4 5 6 7 8 9 const auto & rule = Dune :: QuadratureRules < double , Traits :: mydim >:: rule ( localView_ . element (). type (), order ); Eigen :: VectorXd N ; Eigen :: Matrix < double , Eigen :: Dynamic , gridDim > dN ; for ( auto & gp : rule ){ localFunction . evaluateFunction ( gp . position (), N ); localFunction . evaluateJacobian ( gp . position (), dN ); localFunction . evaluateFunctionAndJacobian ( gp . position (), N , dN ); // (1) } Alternative to the two lines above (Line 6 and 7)","title":"Interface"},{"location":"01_theory/localFunctions/","text":"Local functions \u00b6 This section explains the concept of local functions. Local functions are functions which are bound to single grid elements. Therefore they are constructed from some local basis and a coefficient vector. Usually local functions need to be evaluated in the local coordinate system \\( \\mathbb{\\xi} \\in T_{\\text{ref}} \\subset\\mathbb{R}^n \\) : \\[ f: \\boldsymbol{\\xi}^n \\rightarrow \\mathbb{R}^m \\] where \\(T_{\\text{ref}}\\) is the reference element, e.g. for a cube \\(T_{\\text{ref}}= [0,1]^d\\) . Interface \u00b6 Local functions provide the following interface FunctionReturnType evaluateFunction ( const DomainType & local ); FunctionReturnType evaluateFunction ( const unsigned int & integrationPointIndex ); auto evaluateDerivative ( const DomainType & local ,...); auto evaluateDerivative ( const unsigned int & integrationPointIndex ,...); auto viewOverIntegrationPoints (); // (1) template < std :: size_t ID = 0 > constexpr int order ( Dune :: index_constant < ID > ); // (2) template < std :: size_t ID = 0 > auto basis ( Dune :: index_constant < ID > ); // (3) template < std :: size_t ID = 0 > auto coefficientsRef ( Dune :: index_constant < ID > ); // (4) template < typename IntegrationRule , typename ... Ints > void bind ( IntegrationRule && p_rule , Derivatives < Ints ... >&& ints ); // (5) auto clone (); // (6) template < typename ScalarType , std :: size_t ID = 0 > auto rebindClone ( ScalarType , Dune :: index_constant < ID > ); // (7) This returns a vector of structs of the integration point and its index. Therefore the syntax is usually for ( const auto & [ gpIndex , gp ] : localFunction . viewOverIntegrationPoints ()) {...} Return the order of the local function wrt. the coefficients. An id tag can be passed which returns the order wrt a tagged function. For details see Tagging leaf local functions . Return the basis of the local function. An id tag can be passed which returns the basis of a specific tagged function. For details see Tagging leaf local functions . Returns a reference to the coefficient of the underlying leaf local finite elements. An id tag can be passed which returns the basis of a specific tagged function. It can return const and non-const reference. The non-const version is deactivated, if there are more than one leaf node with the passed id tag. For details see Tagging leaf local functions . This function is passed through to the given localBasis . See Link Clones the local function and stores a copy of all leave nodes. Clones the local function and rebinds the scalar type of the coefficients with id tag ID. This becomes hand, if you want to replace doubles with an autodiff type. The \"...\" in the evaluateDerivative function call are several variadic templates. In action this looks like Usage with integration point index using integration point coordinates using namespace Ikarus :: DerivativeDirections ; localFunction . bind ( rule , bindDerivatives ( 0 , 1 )); for ( auto & [ gpIndex , gp ] : localFunction . viewOverIntegrationPoints ()){ localFunction . evaluateDerivative ( gpIndex , wrt ( spatialAll )); // (1) localFunction . evaluateDerivative ( gpIndex , wrt ( spatialAll ), transformWith ( Jinv )); // (2) } Compute the spatial Jacobian of localFunction Compute the spatial Jacobian of localFunction and transform it to physical coordinates using namespace Ikarus :: DerivativeDirections ; for ( auto & gp : rule ){ localFunction . evaluateDerivative ( gp . position (), wrt ( spatialAll )); // (1) localFunction . evaluateDerivative ( gp . position (), wrt ( spatialAll ), transformWith ( Jinv )); // (2) } Compute the spatial Jacobian of localFunction Compute the spatial Jacobian of localFunction and transform it to physical coordinates where the first call implements \\[ \\operatorname{grad}_\\boldsymbol{\\xi} f : \\boldsymbol{\\xi} \\rightarrow \\mathbb{R}^{m \\times d}. \\] The second one respect the fact that the local function in reality is defined in some physical space \\(X\\) with the coordinate \\(\\boldsymbol{x}\\) . Therefore, it transforms the Jacobian from the reference element \\(\\operatorname{grad}_{\\boldsymbol{\\xi}}\\) to the Jacobian in physical space \\(\\operatorname{grad}_\\boldsymbol{x}\\) . E.g. it usually implements \\[ \\operatorname{grad}_\\boldsymbol{x} = \\operatorname{grad}_{\\boldsymbol{\\xi}} \\boldsymbol{J}^{-1} \\] where \\(J\\) is the Jacobian of the mapping from the reference element \\(T_{\\text{ref}}\\) to the element living in physical space \\(T\\) . For details see 2 page 22. Instead of passing spatialAll to wrt(..) , there are other helper such as localFunction . evaluateDerivative ( gpIndex , wrt ( spatial ( 0 ))); // (1) localFunction . evaluateDerivative ( gpIndex , wrt ( spatial ( 1 ))); // (2) Compute the first column of the spatial Jacobian of localFunction Compute the second column of the spatial Jacobian of localFunction which can also be combined with transformWith(Jinv) . Derivatives w.r.t. coefficients \u00b6 localFunction . evaluateDerivative ( gpIndex , wrt ( coeff ( j ))); which implements for a in vector space valued function (steeming from interpolation),e.g. \\(f(\\boldsymbol{\\xi}) = \\sum_{I=1}^n N^I(\\boldsymbol{\\xi}) \\boldsymbol{x}_I\\) the following \\[ [\\boldsymbol{A}]_{ij} = A_{ij} = \\frac{\\partial f_i(\\boldsymbol{\\xi})}{\\partial \\boldsymbol{x}_j} \\] and the second derivative localFunction . evaluateDerivative ( gpIndex , wrt ( coeff ( j , k )), along ( q )); \\[ [\\boldsymbol{B}]_{jk} = B_{jk} = q_i A_{ijk} = \\frac{\\partial^2 (q_i f_i(\\boldsymbol{\\xi}))}{\\partial \\boldsymbol{x}_j\\partial \\boldsymbol{x}_k} \\] where \\(\\boldsymbol{q}\\) is an arbitrary vector of the same size as \\(f\\) , i.e. it is the direction of the derivative in this case. $ \\boldsymbol{A} $ and $ \\boldsymbol{B} $ is simply the returned matrix and they do not have a special meaning. If we would not pass the vector the result would be a third order tensor for a vector valued function \\(f\\) . Therefore the simply return a matrix. This helps for readablilty and for speed. See the example for details. Derivatives w.r.t. coefficients and spatial derivatives \u00b6 Spatial derivatives and derivatives w.r.t. the coefficients can be combined. Therefore, it is legal to call auto B = localFunction . evaluateDerivative ( gpIndex , wrt ( coeff ( j , k ), spatialAll ), along ( Q )); auto b1 = localFunction . evaluateDerivative ( gpIndex , wrt ( coeff ( j , k ), spatial ( 0 )), along ( q )); auto b2 = localFunction . evaluateDerivative ( gpIndex , wrt ( coeff ( j , k ), spatial ( 1 )), along ( q )); Warning The order of spatial and coeff derivatives does not matter. The returned value is always re-arranged that the first derivative is the spatial one. The first line is then equivalent to \\[ [\\boldsymbol{B}]_{jk} = B_{jk} = Q_{il} A_{iljk} = \\frac{\\partial^2 ([\\operatorname{grad}_\\boldsymbol{\\xi} f(\\boldsymbol{\\xi})]_{il} Q_{il} )}{\\partial \\boldsymbol{x}_j\\partial \\boldsymbol{x}_k}. \\] For the second and third line we have \\[\\begin{align} \\boldsymbol{b}_{0,jk} = \\frac{\\partial^2 ([\\operatorname{grad}_{\\xi^0} f(\\xi)]_{i} q_i )}{\\partial \\boldsymbol{x}_j\\partial \\boldsymbol{x}_k}, \\\\ \\boldsymbol{b}_{1,jk} = \\frac{\\partial^2 ([\\operatorname{grad}_{\\xi^1} f(\\xi)]_{i} q_i )}{\\partial \\boldsymbol{x}_j\\partial \\boldsymbol{x}_k}. \\end{align}\\] These objects are also returned when the second and third line above are used. Again all of these function calls can be combined with transformWith() as localFunction . evaluateDerivative ( gpIndex , wrt ( coeff ( j , k ), spatialAll ), along ( Q ), transformWith ( Jinv )); which computes \\[ \\frac{\\partial^2 ([\\operatorname{grad}_\\boldsymbol{x} f(\\boldsymbol{\\xi})]_{il} Q_{il} )}{\\partial \\boldsymbol{x}_j\\partial \\boldsymbol{x}_k}. \\] Warning Currently only first order spatial derivatives and second order derivatives w.r.t. the coefficients are supported. Example Dirichlet energy \u00b6 This examples shows how the energy, gradient and Hessian of a dirichlet energy can be calculated. $$ E(\\boldsymbol{u}) = \\frac{1}{2} \\int_\\Omega ||\\operatorname{grad}_\\boldsymbol{x} \\boldsymbol{u}(\\boldsymbol{x})|| ^2 \\textrm{d} \\boldsymbol{x} $$ If we want to mimize this energy w.r.t. the coefficients of the nodes, we need to calculate the energy, gradient and the Hessia w.r.t. the coefficents. Of course this depends on the optimization algorithms, but for now lets keep it simple. auto dirichletEnergy () { double energy = 0 ; //... bind localBasis to some integration rule // and create uNodalCoeffs Ikarus :: StandardLocalFunction uFunction ( localBasis , uNodalCoeffs ); for ( const auto & [ gpIndex , gp ] : uFunction . viewOverIntegrationPoints ()) { //.. calculate the inverse Jacobian of the geometry const auto gradu = uFunction . evaluateDerivative ( gpIndex , wrt ( spatialAll ), transformWith ( Jinv )); energy += 0.5 * ( gradu . transpose () * gradu ). trace () * ( \"weight from integration point and geo.integrationElement\" ); } } auto gradientDirichletEnergy ( Eigen :: VectorXd & g ) { //... bind localBasis to some integration rule // and create uNodalCoeffs constexpr int size = // spatial size of u Ikarus :: StandardLocalFunction uFunction ( localBasis , uNodalCoeffs ); for ( const auto & [ gpIndex , gp ] : uFunction . viewOverIntegrationPoints ()) { //.. calculate the inverse Jacobian of the geometry const auto gradu = uFunction . evaluateDerivative ( gpIndex , wrt ( spatialAll ), transformWith ( Jinv )); for ( auto i : fe . size ()) { //loop over coeffs, i.e.nodes of the finite element const auto graduDCoeffs = uFunction . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeffs ), transformWith ( Jinv ), coeffIndices ( i )); Eigen :: Vector < double , size > tmp ; tmp . setZero (); for ( int k = 0 ; k < gridDimension ; ++ k ) tmp += graduDCoeffs [ k ] * gradu . col ( k ); // (1) g . segment < size > ( i * size ) += tmp * ( \"weight from integration point and geo.integrationElement\" ); } } } graduDCoeffs contains in graduDCoeffs[0] the derivatives w.r.t.the coefficient of the first column and at [1] w.r.t.the second colum of gradu auto hessianDirichletEnergy ( Matrix & h ) { //... bind localBasis to some integration rule // and create uNodalCoeffs constexpr int size = // spatial size of u Ikarus :: StandardLocalFunction uFunction ( localBasis , uNodalCoeffs ); for ( const auto & [ gpIndex , gp ] : uFunction . viewOverIntegrationPoints ()) { //.. calculate the inverse Jacobian of the geometry for ( auto i : loop over coeffs , i . e . nodes of the finite element ) { const auto graduDCoeffsI = uFunction . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeffs ), transformWith ( Jinv ), coeffIndices ( i )); for ( auto j : fe . size ()) { //loop over coeffs, i.e.nodes of the finite element const auto graduDCoeffsJ = uFunction . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeffs ), transformWith ( Jinv ), coeffIndices ( j )); Eigen :: Matrix < double , size , size > tmp ; tmp . setZero (); for ( int k = 0 ; k < gridDimension ; ++ k ) tmp += graduDCoeffsI [ k ] * graduDCoeffsJ [ k ]; h . block < size , size > ( i * size , j * size ) += tmp * ( \"weight from integration point and geo.integrationElement\" ); } } } } Implementations \u00b6 In the following we summarize the local functions that are currently available. In the follwing table \\(N^i(\\boldsymbol{\\xi})\\) are the ansatz functions. Name Interpolation formula Note Header Standard $$ \\boldsymbol{x} = \\sum_{i=1}^n N^i(\\boldsymbol{\\xi}) \\boldsymbol{x}_i $$ standardLocalFunction.hh Projection-Based 3 $$ \\boldsymbol{x} = P\\left(\\sum_{i=1}^n N^i(\\boldsymbol{\\xi}) \\boldsymbol{x}_i \\right) $$ This is one version of geometric finite elements. These are finite elements suited for interpolation on manifolds. Here \\(P: \\mathbb{R}^m \\rightarrow \\mathcal{M}\\) is an operator that projects the usual linear interpolation onto some manifold projectionBasedLocalFunction.hh How to implement your own local functions \u00b6 If you are interested in implementing your own local function we have prepared the file ikarus/localFunctions/impl/localFunctionTemplate.hh . You can copy the file rename the class to your preferred name and then implement the following functions. If you don't need a function you need to delete the corresponding function. Then if someone calls the corresponding derivative returns a zero matrix. FunctionReturnType evaluateEmbeddingFunctionImpl ( const Eigen :: VectorXd & N ) const { return FunctionReturnType {}; } // (0) Jacobian evaluateDerivativeWRTSpaceAllImpl ( const AnsatzFunctionType & N , const AnsatzFunctionJacobian & dN ) const {...} // (1) JacobianColType evaluateDerivativeWRTSpaceSingleImpl ( const AnsatzFunctionType & N , const AnsatzFunctionJacobian & dN , int spaceIndex ) const {...} // (2) CoeffDerivMatrix evaluateDerivativeWRTCoeffsImpl ( const AnsatzFunctionType & N , const AnsatzFunctionJacobian & dN , int coeffsIndex ) const {...} // (3) CoeffDerivMatrix evaluateSecondDerivativeWRTCoeffs ( const AnsatzFunctionType & N , const AnsatzFunctionJacobian & , const AlongType & along , const std :: array < size_t , gridDim >& coeffsIndex ) const {...} // (4) std :: array < CoeffDerivMatrix , gridDim > evaluateDerivativeWRTCoeffsANDSpatialImpl ( const AnsatzFunctionType & N , const AnsatzFunctionJacobian & dN , int coeffsIndex ) const {...} // (5) CoeffDerivMatrix evaluateDerivativeWRTCoeffsANDSpatialSingleImpl ( const AnsatzFunctionType & N , const AnsatzFunctionJacobian & dN , const int coeffsIndex , const int spatialIndex ) const {...} // (6) CoeffDerivMatrix evaluateThirdDerivativeWRTCoeffsTwoTimesAndSpatialImpl ( const AnsatzFunctionType & N , const AnsatzFunctionJacobian & dN , const AlongType & along , const std :: array < size_t , gridDim >& coeffsIndex ) const {...} // (7) CoeffDerivMatrix evaluateThirdDerivativeWRTCoeffsTwoTimesAndSpatialSingleImpl ( const AnsatzFunctionType & N , const AnsatzFunctionJacobian & dN , const AlongType & along , const std :: array < size_t , gridDim >& coeffsIndex , c const int spatialIndex ) const {...} // (8) This is called by localFunction.evaluateFunction(...) . This is called by localFunction.evaluateDerivative(..., wrt(spatialAll)) . This is called by localFunction.evaluateDerivative(..., wrt(spatial(i))) . This is called by localFunction.evaluateDerivative(..., wrt(coeff(j))) . This is called by localFunction.evaluateDerivative(..., wrt(coeff(j,k))) . This is called by localFunction.evaluateDerivative(..., wrt(spatialAll,coeff(j))) . This is called by localFunction.evaluateDerivative(..., wrt(spatial(i),coeff(j))) . This is called by localFunction.evaluateDerivative(..., wrt(spatialAll,coeff(j,k)), along(A)) . This is called by localFunction.evaluateDerivative(..., wrt(spatial(i),coeff(j,k)), along(v)) . Expressions \u00b6 We use expression templates 1 to combine existing local functions to obtain new nested ones. For example consider the following code ... auto f = Ikarus :: StandardLocalFunction ( localBasis , coeffVectors0 ); auto g = Ikarus :: StandardLocalFunction ( localBasis , coeffVectors1 ); we create here two local functions that satisfy the interface described above. Now it is possible to combine these functions and get an object that also satisfies the concept above. Thus the following is possible: ... auto f = Ikarus :: StandardLocalFunction ( localBasis , coeffVectors0 ); auto g = Ikarus :: StandardLocalFunction ( localBasis , coeffVectors1 ); auto k = f + g ; k . evaluateDerivative ( ipIndex , wrt ( coeff ( i ), spatial ( d ))); Currently, we support binary and unary expressions. The following expressions are defined: Name Mathematical formula Code Note Sum $$ \\boldsymbol{f} + \\boldsymbol{g} $$ f + g \\(\\boldsymbol{f}\\) and \\(\\boldsymbol{g}\\) need to be the same size. DotProduct $$ \\boldsymbol{f} \\cdot \\boldsymbol{g} = f_i g_i $$ dot ( f , g ) \\(\\boldsymbol{f}\\) and \\(\\boldsymbol{g}\\) need to be the same size. normSquared $$ \\boldsymbol{f} \\cdot \\boldsymbol{f} = f_i f_i $$ normSquared ( f ) Negate $$ -\\boldsymbol{f} $$ - f sqrt $$ \\sqrt{f} $$ sqrt ( f ) The function \\(f\\) needs a scalar return type. Scale $$ a f , \\quad a \\in \\mathbf{R}$$ a * f and f / a a has to satisfy std :: is_arithmetic < .. > These expressions can be nested. Thus, it is valid to write something like auto f = Ikarus :: StandardLocalFunction ( localBasis , coeffVectors0 ); auto g = Ikarus :: StandardLocalFunction ( localBasis , coeffVectors1 ); auto k = - sqrt ( dot ( 2 * f + f , 5 * g )); k . evaluateDerivative ( ipIndex , wrt ( coeff ( i ), spatial ( d ))); To use these expression there are addition exported static types for all expressions constexpr bool isLeaf ; // (1) constexpr bool children ; // (2) This is true if the underlying expression is one of the above Local functions that really contain the coefficients, see Implementations . Returns the number of childs 2 for binary expressions and 1 for unary expressions. Note To use these expression you can simply include the header by #include <ikarus/localFunctions/expressions.hh> . Tagging leaf local functions \u00b6 In the context of mixed finite elements. There are usually several local functions that contribute to the energy. These steems from different local basis. For example consider the Q1P0 element where displacments are interpolated by using the four bilinear ansatz function and the the element-wise constant pressure field. Thus we need to differentiate wrt. different coefficients. This can be done by tagging the local function by construction. using namespace Dune :: Indices ; auto f = Ikarus :: StandardLocalFunction ( localBasis0 , coeffVectors0 , 0 _ ); auto g = Ikarus :: StandardLocalFunction ( localBasis1 , coeffVectors1 , 1 _ ); auto k = dot ( f , g ); k . evaluateDerivative ( ipIndex , wrt ( coeff ( 0 _ , i , 1 _ , j ))); To explain the last line above lets consider that the function f is constructed as \\(f= \\sum_{I=0}^n N^I f_i\\) and similar \\(g= \\sum_{I=0}^m M^I g_i\\) , where \\(N\\) and \\(M\\) are some ansatz functions and \\(f_I\\) and \\(g_I\\) are nodal coefficients. Thus the above call translates to \\[\\begin{align} \\boldsymbol{M}_{0,1}[J,K] = \\frac{\\partial^2 (f_{i} g_i )}{\\partial \\boldsymbol{f}_J\\partial \\boldsymbol{g}_K}. \\end{align}\\] If we would calculate the complete hessian of \\(dot(f,g)\\) we can do this by using namespace Dune :: Indices ; auto hessianDirichletEnergy ( Matrix & h ) { //... bind localBasis to some integration rule using namespace Dune :: Indices ; auto f = Ikarus :: StandardLocalFunction ( localBasis0 , coeffVectors0 , 0 _ ); auto g = Ikarus :: StandardLocalFunction ( localBasis1 , coeffVectors1 , 1 _ ); auto k = dot ( f , g ); constexpr int sizef = f . correctionSize ; // spatial size of the correction of the coefficients of f constexpr int sizeg = g . correctionSize ; // spatial size of the correction of the coefficients of g constexpr int coeffSizef = coeffVectors0 . size (); constexpr int coeffSizeg = coeffVectors1 . size (); Dune :: MultiTypeBlockMatrix < Dune :: MultiTypeBlockVector < MatrixBlock00 , MatrixBlock01 > , Dune :: MultiTypeBlockVector < MatrixBlock10 , MatrixBlock11 > > KBlocked ; // (1) for ( const auto & [ ipIndex , gp ] : k . viewOverIntegrationPoints ()) { for ( size_t I = 0 ; I < coeffSizef ; ++ I ) for ( size_t J = 0 ; J < coeffSizef ; ++ J ) KBlocked [ 0 _ , 0 _ ]. block < sizef , sizef > ( I * sizef , J * sizef ) += k . evaluateDerivative ( ipIndex , wrt ( coeff ( 0 _ , I , 0 _ , J ))) * ( \"weight from integration point and geo.integrationElement\" ); for ( size_t I = 0 ; I < coeffSizef ; ++ I ) for ( size_t J = 0 ; J < coeffSizeg ; ++ J ) KBlocked [ 0 _ , 1 _ ]. block < sizef , sizeg > ( I * sizef , J * sizeg ) += k . evaluateDerivative ( ipIndex , wrt ( coeff ( 0 _ , I , 1 _ , J ))) * ( \"weight from integration point and geo.integrationElement\" ); for ( size_t I = 0 ; I < coeffSizeg ; ++ I ) for ( size_t J = 0 ; J < coeffSizeg ; ++ J ) KBlocked [ 1 _ , 1 _ ]. block < sizeg , sizeg > ( I * sizeg , J * sizeg ) += k . evaluateDerivative ( ipIndex , wrt ( coeff ( 1 _ , I , 1 _ , J ))) * ( \"weight from integration point and geo.integrationElement\" ); for ( size_t I = 0 ; I < coeffSizeg ; ++ I ) for ( size_t J = 0 ; J < coeffSizef ; ++ J ) KBlocked [ 1 _ , 0 _ ]. block < sizef , sizeg > ( I * sizeg , J * sizef ) += k . evaluateDerivative ( ipIndex , wrt ( coeff ( 1 _ , I , 0 _ , J ))) * ( \"weight from integration point and geo.integrationElement\" ); } } This Block structure is not necessary. In this example all types (MatrixBlock00,MatrixBlock01,MatrixBlock10,MatrixBlock11) are considered as Eigen :: MatrixXd . Writing your own expression \u00b6 You can also write your own expressions. For this you can look into existing expressions. Especially the sqrt expression and the normSquared expression are the most general unary and binary expression Implementing the return value \u00b6 If you want to implement your onw expression you first have to implement the return value. This is done using the function template < typename LFArgs > auto evaluateValueOfExpression ( const LFArgs & lfArgs ) const ; Warning The interface dictates that the return value needs to be an Eigen type. Thus, even if you want to return a scalar double you have to wrap it in Eigen :: Vector < double , 1 > Additionally you also have to implement the derivative evaluation. This is done by implementing template < int DerivativeOrder , typename LFArgs > auto evaluateDerivativeOfExpression ( const LFArgs & lfArgs ) const ; Evaluate underlying functions \u00b6 Expression always act on already given expression. Therefore, to return the correct quantity for your expression you have to evaluate the underlying quantities. If you have a unary function you have access to expression using this -> m () and for binary expressions this is this -> l () and this -> r () . To evaluate these functions you can use the following syntax. const auto mEvaluated = evaluateFunctionImpl ( this -> m (), lfArgs ); // (1) The syntax is the same for binary expression, e.g. const auto lEvaluated = evaluateFunctionImpl ( this -> l (), lfArgs ); const auto rEvaluated = evaluateFunctionImpl ( this -> r (), lfArgs ); The expression fulfill the syntax of a local function thus also derivative can be evaluated. In the function evaluateDerivativeOfExpression the derivative order that the user wants is encoded in the template argument DerivativeOrder . Additionally, the derivative types can also accessed using the booleans static constexpr bool hasTwoCoeff ; static constexpr bool hasSingleCoeff ; static constexpr bool hasNoCoeff ; static constexpr bool hasNoSpatial ; static constexpr bool hasOneSpatialAll ; static constexpr bool hasOneSpatialSingle ; static constexpr bool hasOneSpatial ; Using the dotproduct as binary example expression we have template < int DerivativeOrder , typename LFArgs > auto evaluateDerivativeOfExpression ( const LFArgs & lfArgs ) const { const auto u = evaluateFunctionImpl ( this -> l (), lfArgs ); const auto v = evaluateFunctionImpl ( this -> r (), lfArgs ); if constexpr ( DerivativeOrder == 1 ) // (1) { const auto u_x = evaluateDerivativeImpl ( this -> l (), lfArgs ); // (2) const auto v_x = evaluateDerivativeImpl ( this -> r (), lfArgs ); return Ikarus :: eval ( v . transpose () * u_x + u . transpose () * v_x ); // (3) } else if constexpr ( DerivativeOrder == 2 ) { // (4) const auto & [ u_x , u_y ] = evaluateFirstOrderDerivativesImpl ( this -> l (), lfArgs ); // (5) const auto & [ v_x , v_y ] = evaluateFirstOrderDerivativesImpl ( this -> r (), lfArgs ); if constexpr ( LFArgs :: hasNoSpatial and LFArgs :: hasTwoCoeff ) { // (6) const auto alonguArgs = replaceAlong ( lfArgs , along ( v )); // (7) const auto alongvArgs = replaceAlong ( lfArgs , along ( u )); const auto u_xyAlongv = evaluateDerivativeImpl ( this -> l (), alongvArgs ); // (8) const auto v_xyAlongu = evaluateDerivativeImpl ( this -> r (), alonguArgs ); return Ikarus :: eval ( u_xyAlongv + transpose ( u_x ) * v_y + transpose ( v_x ) * u_y + v_xyAlongu ); } else if constexpr ( LFArgs :: hasOneSpatial and LFArgs :: hasSingleCoeff ) { // (9) const auto u_xy = evaluateDerivativeImpl ( this -> l (), lfArgs ); // (10) const auto v_xy = evaluateDerivativeImpl ( this -> r (), lfArgs ); if constexpr ( LFArgs :: hasOneSpatialSingle and LFArgs :: hasSingleCoeff ) { // (11) return Ikarus :: eval ( transpose ( v ) * u_xy + transpose ( u_x ) * v_y + transpose ( v_x ) * u_y + transpose ( u ) * v_xy ); } else if constexpr ( LFArgs :: hasOneSpatialAll and LFArgs :: hasSingleCoeff ) { // (12) std :: array < std :: remove_cvref_t < decltype ( Ikarus :: eval ( transpose ( v ) * u_xy [ 0 ])) > , gridDim > res ; // (13) for ( int i = 0 ; i < gridDim ; ++ i ) res [ i ] = Ikarus :: eval ( transpose ( v ) * u_xy [ i ] + transpose ( u_x . col ( i )) * v_y + transpose ( v_x . col ( i )) * u_y + transpose ( u ) * v_xy [ i ]); return res ; } } } else if constexpr ( DerivativeOrder == 3 ) { // (14) if constexpr ( LFArgs :: hasOneSpatialSingle ) { // (15) const auto argsForDyz = lfArgs . extractSecondWrtArgOrFirstNonSpatial (); // (16) const auto & [ u_x , u_y , u_z ] = evaluateFirstOrderDerivativesImpl ( this -> l (), lfArgs ); // (17) const auto & [ v_x , v_y , v_z ] = evaluateFirstOrderDerivativesImpl ( this -> r (), lfArgs ); const auto & [ u_xy , u_xz ] = evaluateSecondOrderDerivativesImpl ( this -> l (), lfArgs ); // (18) const auto & [ v_xy , v_xz ] = evaluateSecondOrderDerivativesImpl ( this -> r (), lfArgs ); const auto alonguArgs = replaceAlong ( lfArgs , along ( u )); const auto alongvArgs = replaceAlong ( lfArgs , along ( v )); const auto argsForDyzalongv_xArgs = replaceAlong ( argsForDyz , along ( v_x )); // (19) const auto argsForDyzalongu_xArgs = replaceAlong ( argsForDyz , along ( u_x )); const auto u_xyzAlongv = evaluateDerivativeImpl ( this -> l (), alongvArgs ); // (20) const auto v_xyzAlongu = evaluateDerivativeImpl ( this -> r (), alonguArgs ); const auto u_yzAlongvx = evaluateDerivativeImpl ( this -> l (), argsForDyzalongv_xArgs ); // (21) const auto v_yzAlongux = evaluateDerivativeImpl ( this -> r (), argsForDyzalongu_xArgs ); return Ikarus :: eval ( u_xyzAlongv + transpose ( u_xy ) * v_z + transpose ( u_xz ) * v_y + v_yzAlongux + u_yzAlongvx + transpose ( v_xz ) * u_y + transpose ( v_xy ) * u_z + v_xyzAlongu ); } else if constexpr ( LFArgs :: hasOneSpatialAll ) { // (22) const auto & alongMatrix = std :: get < 0 > ( lfArgs . alongArgs . args ); // (23) const auto uTimesA = eval ( u * alongMatrix ); const auto vTimesA = eval ( v * alongMatrix ); const auto & [ gradu , u_c0 , u_c1 ] = evaluateFirstOrderDerivativesImpl ( this -> l (), lfArgs ); // (24) const auto & [ gradv , v_c0 , v_c1 ] = evaluateFirstOrderDerivativesImpl ( this -> r (), lfArgs ); const auto & [ gradu_c0 , gradu_c1 ] = evaluateSecondOrderDerivativesImpl ( this -> l (), lfArgs ); // (25) const auto & [ gradv_c0 , gradv_c1 ] = evaluateSecondOrderDerivativesImpl ( this -> r (), lfArgs ); const auto graduTimesA = ( gradu * alongMatrix . transpose ()). eval (); const auto gradvTimesA = ( gradv * alongMatrix . transpose ()). eval (); const auto argsForDyz = lfArgs . extractSecondWrtArgOrFirstNonSpatial (); const auto alonguAArgs = replaceAlong ( lfArgs , along ( uTimesA )); const auto alongvAArgs = replaceAlong ( lfArgs , along ( vTimesA )); const auto alonggraduTimesAArgs = replaceAlong ( argsForDyz , along ( graduTimesA )); const auto alonggradvTimesAArgs = replaceAlong ( argsForDyz , along ( gradvTimesA )); const auto u_xyzAlongv = evaluateDerivativeImpl ( this -> l (), alongvAArgs ); const auto v_xyzAlongu = evaluateDerivativeImpl ( this -> r (), alonguAArgs ); const auto v_c0c1AlongGraduTimesA = evaluateDerivativeImpl ( this -> r (), alonggraduTimesAArgs ); const auto u_c0c1AlongGradvTimesA = evaluateDerivativeImpl ( this -> l (), alonggradvTimesAArgs ); decltype ( eval ( u_xyzAlongv )) res ; res = u_xyzAlongv + v_xyzAlongu + v_c0c1AlongGraduTimesA + u_c0c1AlongGradvTimesA ; for ( int i = 0 ; i < gridDim ; ++ i ) res += ( transpose ( u_c1 ) * gradv_c0 [ i ] + transpose ( v_c1 ) * gradu_c0 [ i ] + transpose ( v_c0 ) * gradu_c1 [ i ] + transpose ( u_c0 ) * gradv_c1 [ i ]) * alongMatrix ( 0 , i ); return res ; } } } Compile time branch for first order derivatives Evaluates the derivative of the this->l() wrt. the only derivative inside the localfunction arguments lfArgs . Evaluates the return value and derivatives and function values are combined as dictated by the product rule. Compile time branch for second order derivatives Since we are in the second order derivatives branch, there are 4 case for the evaluation of function. The function value, the function derivative wrt. to the first argument or the second and the function's derivatives wrt. to both arguments. Here, the function evaluateFirstOrderDerivativesImpl returns the derivatives wrt. to the first argument and the second. If we consider the left function as \\(\\boldsymbol{u}(\\boldsymbol{\\xi},\\boldsymbol{u}_I)\\) this calls returns \\begin{flalign*} \\verb+u_x+ &= \\frac{\\partial\\boldsymbol{u}}{\\partial\\boldsymbol{\\xi}} \\quad \\text{or} \\quad \\verb+u_x+ = \\frac{\\partial\\boldsymbol{u}}{\\partial\\xi_0} \\quad \\text{or} \\quad \\verb+u_x+ = \\frac{\\partial\\boldsymbol{u}}{\\partial\\boldsymbol{u}_I}\\\\ \\verb+u_y+ &= \\frac{\\partial\\boldsymbol{u}}{\\partial\\boldsymbol{u}_J} \\end{flalign*} The first one would be returned if the caller uses u . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeff ( i ))); and the second one u . evaluateDerivative ( gpIndex , wrt ( spatial ( 0 ), coeff ( i ))); and the third without any spatial derivative using u . evaluateDerivative ( gpIndex , wrt ( coeff ( i , j ))); Therefore, this function seperates the two wrt. arguments and returns the corresponding first order derivatives. Compile time branch for the case where no spatial derivatives are requested bot only wrt. coefficients is needed. Creates a new argument variable where the along argument is replaced by v . This function evaluates the derivatives of l wrt to both passed wrt arguments. Furthmore, it takes the give along argument since otherwise the returned object would be a 3 dimensional array. If we consider the left function as \\(\\boldsymbol{u}(\\boldsymbol{\\xi},\\boldsymbol{u}_I)\\) and \\(\\boldsymbol{v}\\) of the same size as \\(\\boldsymbol{u}\\) this calls returns \\begin{flalign*} \\verb+u_xyAlongv + &= \\frac{\\partial^2 u_i }{\\partial\\boldsymbol{u}_I\\partial\\boldsymbol{u}_J} v_i \\end{flalign*} This is the same if the user calls u . evaluateDerivative ( gpIndex , wrt ( coeff ( i , j )), along ( v )); Compile time branch for the case where one spatial derivatives and one derivative wrt. coefficients is needed. This function evaluates the derivatives of l wrt to both passed wrt arguments. If we consider the left function as \\(\\boldsymbol{u}(\\boldsymbol{\\xi},\\boldsymbol{u}_I)\\) this calls returns \\begin{flalign*} \\verb+u_xy+ &= \\frac{\\partial^2 \\boldsymbol{u} }{\\partial\\boldsymbol{\\xi}\\partial\\boldsymbol{u}_I} \\quad \\text{or} \\quad \\verb+u_xy+ = \\frac{\\partial^2 \\boldsymbol{u} }{\\partial\\xi_0\\partial\\boldsymbol{u}_I} \\end{flalign*} The first one would be returned if the caller uses u . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeff ( i ))); and the second one u . evaluateDerivative ( gpIndex , wrt ( spatial ( 0 ), coeff ( i ))); In the first case the result is stored in an array. Thus in the first index the derivative wrt. to the first spatial coordinate is stored. Therefore we would have in the code spatialAllCoeffDeriv = u . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeff ( i ))); spatialAllCoeffDeriv [ 0 ] // derivative as in u.evaluateDerivative(gpIndex, wrt(spatial(0),coeff(i))); spatialAllCoeffDeriv [ 1 ] // derivative as in u.evaluateDerivative(gpIndex, wrt(spatial(1),coeff(i))); Compile time branch for the case where one single spatial derivatives and one derivative wrt. coefficients is needed. Compile time branch for the case where all spatial derivatives and one derivative wrt. coefficients is needed. The return type here is an array of single spatial derivatives and each derived wrt. the coefficient. Thus the type inside the array must be deduced here. Compile time branch for third order derivatives Compile time branch for single spatial derivatives To obtain derivatives wrt to the second and third wrt argument we extract here the arguments. E.g. if we have the following request u . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeff ( i , j )), along ( matrix )); this call would extract the arguments as newArgs = \"wrt(coeff(i,j)),along(matrix))\" //THIS IS NO VALID SYNTAX This can be used then as u . evaluateDerivative ( gpIndex , newArgs ); As in the second order derivative case the returns all three first order derivatives. If we would have u . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeff ( i , j )), along ( matrix )); The returned values would be \\begin{flalign*} \\verb+u_x+ &= \\frac{\\partial \\boldsymbol{u} }{\\partial\\boldsymbol{\\xi}} \\\\ \\verb+u_y+ &= \\frac{\\partial \\boldsymbol{u} }{\\partial\\boldsymbol{u}_I} \\\\ \\verb+u_z+ &= \\frac{\\partial \\boldsymbol{u} }{\\partial\\boldsymbol{u}_J} \\end{flalign*} This returns the derivatives wrt to the given spatial direction and wrt to the first and second coefficient. If we would have u . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeff ( i , j )), along ( matrix )); The returned values would be \\begin{flalign*} \\verb+u_xy+ &= \\frac{\\partial^2 \\boldsymbol{u} }{\\partial\\boldsymbol{\\xi}\\partial\\boldsymbol{u}_I} \\\\ \\verb+u_xz+ &= \\frac{\\partial^2 \\boldsymbol{u} }{\\partial\\boldsymbol{\\xi}\\partial\\boldsymbol{u}_J} \\\\ \\end{flalign*} Creates a new argument variable where the along argument is replaced by v_x . This return as the call would be u . evaluateDerivative ( gpIndex , wrt ( spatial ( 0 ), coeff ( i , j ), along ( v )); In mathematical notation this returns \\begin{flalign*} \\verb+u_xyzAlongv + &= \\frac{\\partial^3 u_i }{\\partial \\xi_0\\partial\\boldsymbol{u}_I\\partial\\boldsymbol{u}_J} v_i \\end{flalign*} This return as the call would be v_x = v . evaluateDerivative ( gpIndex , wrt ( spatial ( 0 )); u_yzAlongvx = u . evaluateDerivative ( gpIndex , wrt ( coeff ( i , j ), along ( v_x )); In mathematical notation this returns \\begin{flalign*} \\verb+u_yzAlongvx+ &= \\frac{\\partial^2 u_i }{\\partial\\boldsymbol{u}_I\\partial\\boldsymbol{u}_J} \\left[\\frac{\\partial \\boldsymbol{v}}{\\xi_0}\\right]_i \\end{flalign*} Compile time branch for all spatial derivatives Obtain the along argument give by the caller as in u . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeff ( i , j ), along ( matrix )); As above in the single spatial case As above in the single spatial case If your expression is working you should add it to ikarus/localfunctions/expressions.hh Expression templates are usually used in linear algebra libraries, e.g. Eigen or Blaze . The syntax is similar to the one provided by UML but only acts on local functions. \u21a9 Oliver Sander. DUNE\u2014The Distributed and Unified Numerics Environment . Volume 140. Springer Nature, 2020. URL: https://link.springer.com/book/10.1007/978-3-030-59702-3 . \u21a9 Philipp Grohs, Hanne Hardering, Oliver Sander, and Markus Sprecher. Projection-based finite elements for nonlinear function spaces. SIAM J Numer Anal , 57(1):404\u2013428, 2019. doi:10.1137/18M1176798 . \u21a9","title":"Local functions"},{"location":"01_theory/localFunctions/#local-functions","text":"This section explains the concept of local functions. Local functions are functions which are bound to single grid elements. Therefore they are constructed from some local basis and a coefficient vector. Usually local functions need to be evaluated in the local coordinate system \\( \\mathbb{\\xi} \\in T_{\\text{ref}} \\subset\\mathbb{R}^n \\) : \\[ f: \\boldsymbol{\\xi}^n \\rightarrow \\mathbb{R}^m \\] where \\(T_{\\text{ref}}\\) is the reference element, e.g. for a cube \\(T_{\\text{ref}}= [0,1]^d\\) .","title":"Local functions"},{"location":"01_theory/localFunctions/#interface","text":"Local functions provide the following interface FunctionReturnType evaluateFunction ( const DomainType & local ); FunctionReturnType evaluateFunction ( const unsigned int & integrationPointIndex ); auto evaluateDerivative ( const DomainType & local ,...); auto evaluateDerivative ( const unsigned int & integrationPointIndex ,...); auto viewOverIntegrationPoints (); // (1) template < std :: size_t ID = 0 > constexpr int order ( Dune :: index_constant < ID > ); // (2) template < std :: size_t ID = 0 > auto basis ( Dune :: index_constant < ID > ); // (3) template < std :: size_t ID = 0 > auto coefficientsRef ( Dune :: index_constant < ID > ); // (4) template < typename IntegrationRule , typename ... Ints > void bind ( IntegrationRule && p_rule , Derivatives < Ints ... >&& ints ); // (5) auto clone (); // (6) template < typename ScalarType , std :: size_t ID = 0 > auto rebindClone ( ScalarType , Dune :: index_constant < ID > ); // (7) This returns a vector of structs of the integration point and its index. Therefore the syntax is usually for ( const auto & [ gpIndex , gp ] : localFunction . viewOverIntegrationPoints ()) {...} Return the order of the local function wrt. the coefficients. An id tag can be passed which returns the order wrt a tagged function. For details see Tagging leaf local functions . Return the basis of the local function. An id tag can be passed which returns the basis of a specific tagged function. For details see Tagging leaf local functions . Returns a reference to the coefficient of the underlying leaf local finite elements. An id tag can be passed which returns the basis of a specific tagged function. It can return const and non-const reference. The non-const version is deactivated, if there are more than one leaf node with the passed id tag. For details see Tagging leaf local functions . This function is passed through to the given localBasis . See Link Clones the local function and stores a copy of all leave nodes. Clones the local function and rebinds the scalar type of the coefficients with id tag ID. This becomes hand, if you want to replace doubles with an autodiff type. The \"...\" in the evaluateDerivative function call are several variadic templates. In action this looks like Usage with integration point index using integration point coordinates using namespace Ikarus :: DerivativeDirections ; localFunction . bind ( rule , bindDerivatives ( 0 , 1 )); for ( auto & [ gpIndex , gp ] : localFunction . viewOverIntegrationPoints ()){ localFunction . evaluateDerivative ( gpIndex , wrt ( spatialAll )); // (1) localFunction . evaluateDerivative ( gpIndex , wrt ( spatialAll ), transformWith ( Jinv )); // (2) } Compute the spatial Jacobian of localFunction Compute the spatial Jacobian of localFunction and transform it to physical coordinates using namespace Ikarus :: DerivativeDirections ; for ( auto & gp : rule ){ localFunction . evaluateDerivative ( gp . position (), wrt ( spatialAll )); // (1) localFunction . evaluateDerivative ( gp . position (), wrt ( spatialAll ), transformWith ( Jinv )); // (2) } Compute the spatial Jacobian of localFunction Compute the spatial Jacobian of localFunction and transform it to physical coordinates where the first call implements \\[ \\operatorname{grad}_\\boldsymbol{\\xi} f : \\boldsymbol{\\xi} \\rightarrow \\mathbb{R}^{m \\times d}. \\] The second one respect the fact that the local function in reality is defined in some physical space \\(X\\) with the coordinate \\(\\boldsymbol{x}\\) . Therefore, it transforms the Jacobian from the reference element \\(\\operatorname{grad}_{\\boldsymbol{\\xi}}\\) to the Jacobian in physical space \\(\\operatorname{grad}_\\boldsymbol{x}\\) . E.g. it usually implements \\[ \\operatorname{grad}_\\boldsymbol{x} = \\operatorname{grad}_{\\boldsymbol{\\xi}} \\boldsymbol{J}^{-1} \\] where \\(J\\) is the Jacobian of the mapping from the reference element \\(T_{\\text{ref}}\\) to the element living in physical space \\(T\\) . For details see 2 page 22. Instead of passing spatialAll to wrt(..) , there are other helper such as localFunction . evaluateDerivative ( gpIndex , wrt ( spatial ( 0 ))); // (1) localFunction . evaluateDerivative ( gpIndex , wrt ( spatial ( 1 ))); // (2) Compute the first column of the spatial Jacobian of localFunction Compute the second column of the spatial Jacobian of localFunction which can also be combined with transformWith(Jinv) .","title":"Interface"},{"location":"01_theory/localFunctions/#derivatives-wrt-coefficients","text":"localFunction . evaluateDerivative ( gpIndex , wrt ( coeff ( j ))); which implements for a in vector space valued function (steeming from interpolation),e.g. \\(f(\\boldsymbol{\\xi}) = \\sum_{I=1}^n N^I(\\boldsymbol{\\xi}) \\boldsymbol{x}_I\\) the following \\[ [\\boldsymbol{A}]_{ij} = A_{ij} = \\frac{\\partial f_i(\\boldsymbol{\\xi})}{\\partial \\boldsymbol{x}_j} \\] and the second derivative localFunction . evaluateDerivative ( gpIndex , wrt ( coeff ( j , k )), along ( q )); \\[ [\\boldsymbol{B}]_{jk} = B_{jk} = q_i A_{ijk} = \\frac{\\partial^2 (q_i f_i(\\boldsymbol{\\xi}))}{\\partial \\boldsymbol{x}_j\\partial \\boldsymbol{x}_k} \\] where \\(\\boldsymbol{q}\\) is an arbitrary vector of the same size as \\(f\\) , i.e. it is the direction of the derivative in this case. $ \\boldsymbol{A} $ and $ \\boldsymbol{B} $ is simply the returned matrix and they do not have a special meaning. If we would not pass the vector the result would be a third order tensor for a vector valued function \\(f\\) . Therefore the simply return a matrix. This helps for readablilty and for speed. See the example for details.","title":"Derivatives w.r.t. coefficients"},{"location":"01_theory/localFunctions/#derivatives-wrt-coefficients-and-spatial-derivatives","text":"Spatial derivatives and derivatives w.r.t. the coefficients can be combined. Therefore, it is legal to call auto B = localFunction . evaluateDerivative ( gpIndex , wrt ( coeff ( j , k ), spatialAll ), along ( Q )); auto b1 = localFunction . evaluateDerivative ( gpIndex , wrt ( coeff ( j , k ), spatial ( 0 )), along ( q )); auto b2 = localFunction . evaluateDerivative ( gpIndex , wrt ( coeff ( j , k ), spatial ( 1 )), along ( q )); Warning The order of spatial and coeff derivatives does not matter. The returned value is always re-arranged that the first derivative is the spatial one. The first line is then equivalent to \\[ [\\boldsymbol{B}]_{jk} = B_{jk} = Q_{il} A_{iljk} = \\frac{\\partial^2 ([\\operatorname{grad}_\\boldsymbol{\\xi} f(\\boldsymbol{\\xi})]_{il} Q_{il} )}{\\partial \\boldsymbol{x}_j\\partial \\boldsymbol{x}_k}. \\] For the second and third line we have \\[\\begin{align} \\boldsymbol{b}_{0,jk} = \\frac{\\partial^2 ([\\operatorname{grad}_{\\xi^0} f(\\xi)]_{i} q_i )}{\\partial \\boldsymbol{x}_j\\partial \\boldsymbol{x}_k}, \\\\ \\boldsymbol{b}_{1,jk} = \\frac{\\partial^2 ([\\operatorname{grad}_{\\xi^1} f(\\xi)]_{i} q_i )}{\\partial \\boldsymbol{x}_j\\partial \\boldsymbol{x}_k}. \\end{align}\\] These objects are also returned when the second and third line above are used. Again all of these function calls can be combined with transformWith() as localFunction . evaluateDerivative ( gpIndex , wrt ( coeff ( j , k ), spatialAll ), along ( Q ), transformWith ( Jinv )); which computes \\[ \\frac{\\partial^2 ([\\operatorname{grad}_\\boldsymbol{x} f(\\boldsymbol{\\xi})]_{il} Q_{il} )}{\\partial \\boldsymbol{x}_j\\partial \\boldsymbol{x}_k}. \\] Warning Currently only first order spatial derivatives and second order derivatives w.r.t. the coefficients are supported.","title":"Derivatives w.r.t. coefficients and spatial derivatives"},{"location":"01_theory/localFunctions/#example-dirichlet-energy","text":"This examples shows how the energy, gradient and Hessian of a dirichlet energy can be calculated. $$ E(\\boldsymbol{u}) = \\frac{1}{2} \\int_\\Omega ||\\operatorname{grad}_\\boldsymbol{x} \\boldsymbol{u}(\\boldsymbol{x})|| ^2 \\textrm{d} \\boldsymbol{x} $$ If we want to mimize this energy w.r.t. the coefficients of the nodes, we need to calculate the energy, gradient and the Hessia w.r.t. the coefficents. Of course this depends on the optimization algorithms, but for now lets keep it simple. auto dirichletEnergy () { double energy = 0 ; //... bind localBasis to some integration rule // and create uNodalCoeffs Ikarus :: StandardLocalFunction uFunction ( localBasis , uNodalCoeffs ); for ( const auto & [ gpIndex , gp ] : uFunction . viewOverIntegrationPoints ()) { //.. calculate the inverse Jacobian of the geometry const auto gradu = uFunction . evaluateDerivative ( gpIndex , wrt ( spatialAll ), transformWith ( Jinv )); energy += 0.5 * ( gradu . transpose () * gradu ). trace () * ( \"weight from integration point and geo.integrationElement\" ); } } auto gradientDirichletEnergy ( Eigen :: VectorXd & g ) { //... bind localBasis to some integration rule // and create uNodalCoeffs constexpr int size = // spatial size of u Ikarus :: StandardLocalFunction uFunction ( localBasis , uNodalCoeffs ); for ( const auto & [ gpIndex , gp ] : uFunction . viewOverIntegrationPoints ()) { //.. calculate the inverse Jacobian of the geometry const auto gradu = uFunction . evaluateDerivative ( gpIndex , wrt ( spatialAll ), transformWith ( Jinv )); for ( auto i : fe . size ()) { //loop over coeffs, i.e.nodes of the finite element const auto graduDCoeffs = uFunction . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeffs ), transformWith ( Jinv ), coeffIndices ( i )); Eigen :: Vector < double , size > tmp ; tmp . setZero (); for ( int k = 0 ; k < gridDimension ; ++ k ) tmp += graduDCoeffs [ k ] * gradu . col ( k ); // (1) g . segment < size > ( i * size ) += tmp * ( \"weight from integration point and geo.integrationElement\" ); } } } graduDCoeffs contains in graduDCoeffs[0] the derivatives w.r.t.the coefficient of the first column and at [1] w.r.t.the second colum of gradu auto hessianDirichletEnergy ( Matrix & h ) { //... bind localBasis to some integration rule // and create uNodalCoeffs constexpr int size = // spatial size of u Ikarus :: StandardLocalFunction uFunction ( localBasis , uNodalCoeffs ); for ( const auto & [ gpIndex , gp ] : uFunction . viewOverIntegrationPoints ()) { //.. calculate the inverse Jacobian of the geometry for ( auto i : loop over coeffs , i . e . nodes of the finite element ) { const auto graduDCoeffsI = uFunction . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeffs ), transformWith ( Jinv ), coeffIndices ( i )); for ( auto j : fe . size ()) { //loop over coeffs, i.e.nodes of the finite element const auto graduDCoeffsJ = uFunction . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeffs ), transformWith ( Jinv ), coeffIndices ( j )); Eigen :: Matrix < double , size , size > tmp ; tmp . setZero (); for ( int k = 0 ; k < gridDimension ; ++ k ) tmp += graduDCoeffsI [ k ] * graduDCoeffsJ [ k ]; h . block < size , size > ( i * size , j * size ) += tmp * ( \"weight from integration point and geo.integrationElement\" ); } } } }","title":"Example Dirichlet energy"},{"location":"01_theory/localFunctions/#implementations","text":"In the following we summarize the local functions that are currently available. In the follwing table \\(N^i(\\boldsymbol{\\xi})\\) are the ansatz functions. Name Interpolation formula Note Header Standard $$ \\boldsymbol{x} = \\sum_{i=1}^n N^i(\\boldsymbol{\\xi}) \\boldsymbol{x}_i $$ standardLocalFunction.hh Projection-Based 3 $$ \\boldsymbol{x} = P\\left(\\sum_{i=1}^n N^i(\\boldsymbol{\\xi}) \\boldsymbol{x}_i \\right) $$ This is one version of geometric finite elements. These are finite elements suited for interpolation on manifolds. Here \\(P: \\mathbb{R}^m \\rightarrow \\mathcal{M}\\) is an operator that projects the usual linear interpolation onto some manifold projectionBasedLocalFunction.hh","title":"Implementations"},{"location":"01_theory/localFunctions/#how-to-implement-your-own-local-functions","text":"If you are interested in implementing your own local function we have prepared the file ikarus/localFunctions/impl/localFunctionTemplate.hh . You can copy the file rename the class to your preferred name and then implement the following functions. If you don't need a function you need to delete the corresponding function. Then if someone calls the corresponding derivative returns a zero matrix. FunctionReturnType evaluateEmbeddingFunctionImpl ( const Eigen :: VectorXd & N ) const { return FunctionReturnType {}; } // (0) Jacobian evaluateDerivativeWRTSpaceAllImpl ( const AnsatzFunctionType & N , const AnsatzFunctionJacobian & dN ) const {...} // (1) JacobianColType evaluateDerivativeWRTSpaceSingleImpl ( const AnsatzFunctionType & N , const AnsatzFunctionJacobian & dN , int spaceIndex ) const {...} // (2) CoeffDerivMatrix evaluateDerivativeWRTCoeffsImpl ( const AnsatzFunctionType & N , const AnsatzFunctionJacobian & dN , int coeffsIndex ) const {...} // (3) CoeffDerivMatrix evaluateSecondDerivativeWRTCoeffs ( const AnsatzFunctionType & N , const AnsatzFunctionJacobian & , const AlongType & along , const std :: array < size_t , gridDim >& coeffsIndex ) const {...} // (4) std :: array < CoeffDerivMatrix , gridDim > evaluateDerivativeWRTCoeffsANDSpatialImpl ( const AnsatzFunctionType & N , const AnsatzFunctionJacobian & dN , int coeffsIndex ) const {...} // (5) CoeffDerivMatrix evaluateDerivativeWRTCoeffsANDSpatialSingleImpl ( const AnsatzFunctionType & N , const AnsatzFunctionJacobian & dN , const int coeffsIndex , const int spatialIndex ) const {...} // (6) CoeffDerivMatrix evaluateThirdDerivativeWRTCoeffsTwoTimesAndSpatialImpl ( const AnsatzFunctionType & N , const AnsatzFunctionJacobian & dN , const AlongType & along , const std :: array < size_t , gridDim >& coeffsIndex ) const {...} // (7) CoeffDerivMatrix evaluateThirdDerivativeWRTCoeffsTwoTimesAndSpatialSingleImpl ( const AnsatzFunctionType & N , const AnsatzFunctionJacobian & dN , const AlongType & along , const std :: array < size_t , gridDim >& coeffsIndex , c const int spatialIndex ) const {...} // (8) This is called by localFunction.evaluateFunction(...) . This is called by localFunction.evaluateDerivative(..., wrt(spatialAll)) . This is called by localFunction.evaluateDerivative(..., wrt(spatial(i))) . This is called by localFunction.evaluateDerivative(..., wrt(coeff(j))) . This is called by localFunction.evaluateDerivative(..., wrt(coeff(j,k))) . This is called by localFunction.evaluateDerivative(..., wrt(spatialAll,coeff(j))) . This is called by localFunction.evaluateDerivative(..., wrt(spatial(i),coeff(j))) . This is called by localFunction.evaluateDerivative(..., wrt(spatialAll,coeff(j,k)), along(A)) . This is called by localFunction.evaluateDerivative(..., wrt(spatial(i),coeff(j,k)), along(v)) .","title":"How to implement your own local functions"},{"location":"01_theory/localFunctions/#expressions","text":"We use expression templates 1 to combine existing local functions to obtain new nested ones. For example consider the following code ... auto f = Ikarus :: StandardLocalFunction ( localBasis , coeffVectors0 ); auto g = Ikarus :: StandardLocalFunction ( localBasis , coeffVectors1 ); we create here two local functions that satisfy the interface described above. Now it is possible to combine these functions and get an object that also satisfies the concept above. Thus the following is possible: ... auto f = Ikarus :: StandardLocalFunction ( localBasis , coeffVectors0 ); auto g = Ikarus :: StandardLocalFunction ( localBasis , coeffVectors1 ); auto k = f + g ; k . evaluateDerivative ( ipIndex , wrt ( coeff ( i ), spatial ( d ))); Currently, we support binary and unary expressions. The following expressions are defined: Name Mathematical formula Code Note Sum $$ \\boldsymbol{f} + \\boldsymbol{g} $$ f + g \\(\\boldsymbol{f}\\) and \\(\\boldsymbol{g}\\) need to be the same size. DotProduct $$ \\boldsymbol{f} \\cdot \\boldsymbol{g} = f_i g_i $$ dot ( f , g ) \\(\\boldsymbol{f}\\) and \\(\\boldsymbol{g}\\) need to be the same size. normSquared $$ \\boldsymbol{f} \\cdot \\boldsymbol{f} = f_i f_i $$ normSquared ( f ) Negate $$ -\\boldsymbol{f} $$ - f sqrt $$ \\sqrt{f} $$ sqrt ( f ) The function \\(f\\) needs a scalar return type. Scale $$ a f , \\quad a \\in \\mathbf{R}$$ a * f and f / a a has to satisfy std :: is_arithmetic < .. > These expressions can be nested. Thus, it is valid to write something like auto f = Ikarus :: StandardLocalFunction ( localBasis , coeffVectors0 ); auto g = Ikarus :: StandardLocalFunction ( localBasis , coeffVectors1 ); auto k = - sqrt ( dot ( 2 * f + f , 5 * g )); k . evaluateDerivative ( ipIndex , wrt ( coeff ( i ), spatial ( d ))); To use these expression there are addition exported static types for all expressions constexpr bool isLeaf ; // (1) constexpr bool children ; // (2) This is true if the underlying expression is one of the above Local functions that really contain the coefficients, see Implementations . Returns the number of childs 2 for binary expressions and 1 for unary expressions. Note To use these expression you can simply include the header by #include <ikarus/localFunctions/expressions.hh> .","title":"Expressions"},{"location":"01_theory/localFunctions/#tagging-leaf-local-functions","text":"In the context of mixed finite elements. There are usually several local functions that contribute to the energy. These steems from different local basis. For example consider the Q1P0 element where displacments are interpolated by using the four bilinear ansatz function and the the element-wise constant pressure field. Thus we need to differentiate wrt. different coefficients. This can be done by tagging the local function by construction. using namespace Dune :: Indices ; auto f = Ikarus :: StandardLocalFunction ( localBasis0 , coeffVectors0 , 0 _ ); auto g = Ikarus :: StandardLocalFunction ( localBasis1 , coeffVectors1 , 1 _ ); auto k = dot ( f , g ); k . evaluateDerivative ( ipIndex , wrt ( coeff ( 0 _ , i , 1 _ , j ))); To explain the last line above lets consider that the function f is constructed as \\(f= \\sum_{I=0}^n N^I f_i\\) and similar \\(g= \\sum_{I=0}^m M^I g_i\\) , where \\(N\\) and \\(M\\) are some ansatz functions and \\(f_I\\) and \\(g_I\\) are nodal coefficients. Thus the above call translates to \\[\\begin{align} \\boldsymbol{M}_{0,1}[J,K] = \\frac{\\partial^2 (f_{i} g_i )}{\\partial \\boldsymbol{f}_J\\partial \\boldsymbol{g}_K}. \\end{align}\\] If we would calculate the complete hessian of \\(dot(f,g)\\) we can do this by using namespace Dune :: Indices ; auto hessianDirichletEnergy ( Matrix & h ) { //... bind localBasis to some integration rule using namespace Dune :: Indices ; auto f = Ikarus :: StandardLocalFunction ( localBasis0 , coeffVectors0 , 0 _ ); auto g = Ikarus :: StandardLocalFunction ( localBasis1 , coeffVectors1 , 1 _ ); auto k = dot ( f , g ); constexpr int sizef = f . correctionSize ; // spatial size of the correction of the coefficients of f constexpr int sizeg = g . correctionSize ; // spatial size of the correction of the coefficients of g constexpr int coeffSizef = coeffVectors0 . size (); constexpr int coeffSizeg = coeffVectors1 . size (); Dune :: MultiTypeBlockMatrix < Dune :: MultiTypeBlockVector < MatrixBlock00 , MatrixBlock01 > , Dune :: MultiTypeBlockVector < MatrixBlock10 , MatrixBlock11 > > KBlocked ; // (1) for ( const auto & [ ipIndex , gp ] : k . viewOverIntegrationPoints ()) { for ( size_t I = 0 ; I < coeffSizef ; ++ I ) for ( size_t J = 0 ; J < coeffSizef ; ++ J ) KBlocked [ 0 _ , 0 _ ]. block < sizef , sizef > ( I * sizef , J * sizef ) += k . evaluateDerivative ( ipIndex , wrt ( coeff ( 0 _ , I , 0 _ , J ))) * ( \"weight from integration point and geo.integrationElement\" ); for ( size_t I = 0 ; I < coeffSizef ; ++ I ) for ( size_t J = 0 ; J < coeffSizeg ; ++ J ) KBlocked [ 0 _ , 1 _ ]. block < sizef , sizeg > ( I * sizef , J * sizeg ) += k . evaluateDerivative ( ipIndex , wrt ( coeff ( 0 _ , I , 1 _ , J ))) * ( \"weight from integration point and geo.integrationElement\" ); for ( size_t I = 0 ; I < coeffSizeg ; ++ I ) for ( size_t J = 0 ; J < coeffSizeg ; ++ J ) KBlocked [ 1 _ , 1 _ ]. block < sizeg , sizeg > ( I * sizeg , J * sizeg ) += k . evaluateDerivative ( ipIndex , wrt ( coeff ( 1 _ , I , 1 _ , J ))) * ( \"weight from integration point and geo.integrationElement\" ); for ( size_t I = 0 ; I < coeffSizeg ; ++ I ) for ( size_t J = 0 ; J < coeffSizef ; ++ J ) KBlocked [ 1 _ , 0 _ ]. block < sizef , sizeg > ( I * sizeg , J * sizef ) += k . evaluateDerivative ( ipIndex , wrt ( coeff ( 1 _ , I , 0 _ , J ))) * ( \"weight from integration point and geo.integrationElement\" ); } } This Block structure is not necessary. In this example all types (MatrixBlock00,MatrixBlock01,MatrixBlock10,MatrixBlock11) are considered as Eigen :: MatrixXd .","title":"Tagging leaf local functions"},{"location":"01_theory/localFunctions/#writing-your-own-expression","text":"You can also write your own expressions. For this you can look into existing expressions. Especially the sqrt expression and the normSquared expression are the most general unary and binary expression","title":"Writing your own expression"},{"location":"01_theory/localFunctions/#implementing-the-return-value","text":"If you want to implement your onw expression you first have to implement the return value. This is done using the function template < typename LFArgs > auto evaluateValueOfExpression ( const LFArgs & lfArgs ) const ; Warning The interface dictates that the return value needs to be an Eigen type. Thus, even if you want to return a scalar double you have to wrap it in Eigen :: Vector < double , 1 > Additionally you also have to implement the derivative evaluation. This is done by implementing template < int DerivativeOrder , typename LFArgs > auto evaluateDerivativeOfExpression ( const LFArgs & lfArgs ) const ;","title":"Implementing the return value"},{"location":"01_theory/localFunctions/#evaluate-underlying-functions","text":"Expression always act on already given expression. Therefore, to return the correct quantity for your expression you have to evaluate the underlying quantities. If you have a unary function you have access to expression using this -> m () and for binary expressions this is this -> l () and this -> r () . To evaluate these functions you can use the following syntax. const auto mEvaluated = evaluateFunctionImpl ( this -> m (), lfArgs ); // (1) The syntax is the same for binary expression, e.g. const auto lEvaluated = evaluateFunctionImpl ( this -> l (), lfArgs ); const auto rEvaluated = evaluateFunctionImpl ( this -> r (), lfArgs ); The expression fulfill the syntax of a local function thus also derivative can be evaluated. In the function evaluateDerivativeOfExpression the derivative order that the user wants is encoded in the template argument DerivativeOrder . Additionally, the derivative types can also accessed using the booleans static constexpr bool hasTwoCoeff ; static constexpr bool hasSingleCoeff ; static constexpr bool hasNoCoeff ; static constexpr bool hasNoSpatial ; static constexpr bool hasOneSpatialAll ; static constexpr bool hasOneSpatialSingle ; static constexpr bool hasOneSpatial ; Using the dotproduct as binary example expression we have template < int DerivativeOrder , typename LFArgs > auto evaluateDerivativeOfExpression ( const LFArgs & lfArgs ) const { const auto u = evaluateFunctionImpl ( this -> l (), lfArgs ); const auto v = evaluateFunctionImpl ( this -> r (), lfArgs ); if constexpr ( DerivativeOrder == 1 ) // (1) { const auto u_x = evaluateDerivativeImpl ( this -> l (), lfArgs ); // (2) const auto v_x = evaluateDerivativeImpl ( this -> r (), lfArgs ); return Ikarus :: eval ( v . transpose () * u_x + u . transpose () * v_x ); // (3) } else if constexpr ( DerivativeOrder == 2 ) { // (4) const auto & [ u_x , u_y ] = evaluateFirstOrderDerivativesImpl ( this -> l (), lfArgs ); // (5) const auto & [ v_x , v_y ] = evaluateFirstOrderDerivativesImpl ( this -> r (), lfArgs ); if constexpr ( LFArgs :: hasNoSpatial and LFArgs :: hasTwoCoeff ) { // (6) const auto alonguArgs = replaceAlong ( lfArgs , along ( v )); // (7) const auto alongvArgs = replaceAlong ( lfArgs , along ( u )); const auto u_xyAlongv = evaluateDerivativeImpl ( this -> l (), alongvArgs ); // (8) const auto v_xyAlongu = evaluateDerivativeImpl ( this -> r (), alonguArgs ); return Ikarus :: eval ( u_xyAlongv + transpose ( u_x ) * v_y + transpose ( v_x ) * u_y + v_xyAlongu ); } else if constexpr ( LFArgs :: hasOneSpatial and LFArgs :: hasSingleCoeff ) { // (9) const auto u_xy = evaluateDerivativeImpl ( this -> l (), lfArgs ); // (10) const auto v_xy = evaluateDerivativeImpl ( this -> r (), lfArgs ); if constexpr ( LFArgs :: hasOneSpatialSingle and LFArgs :: hasSingleCoeff ) { // (11) return Ikarus :: eval ( transpose ( v ) * u_xy + transpose ( u_x ) * v_y + transpose ( v_x ) * u_y + transpose ( u ) * v_xy ); } else if constexpr ( LFArgs :: hasOneSpatialAll and LFArgs :: hasSingleCoeff ) { // (12) std :: array < std :: remove_cvref_t < decltype ( Ikarus :: eval ( transpose ( v ) * u_xy [ 0 ])) > , gridDim > res ; // (13) for ( int i = 0 ; i < gridDim ; ++ i ) res [ i ] = Ikarus :: eval ( transpose ( v ) * u_xy [ i ] + transpose ( u_x . col ( i )) * v_y + transpose ( v_x . col ( i )) * u_y + transpose ( u ) * v_xy [ i ]); return res ; } } } else if constexpr ( DerivativeOrder == 3 ) { // (14) if constexpr ( LFArgs :: hasOneSpatialSingle ) { // (15) const auto argsForDyz = lfArgs . extractSecondWrtArgOrFirstNonSpatial (); // (16) const auto & [ u_x , u_y , u_z ] = evaluateFirstOrderDerivativesImpl ( this -> l (), lfArgs ); // (17) const auto & [ v_x , v_y , v_z ] = evaluateFirstOrderDerivativesImpl ( this -> r (), lfArgs ); const auto & [ u_xy , u_xz ] = evaluateSecondOrderDerivativesImpl ( this -> l (), lfArgs ); // (18) const auto & [ v_xy , v_xz ] = evaluateSecondOrderDerivativesImpl ( this -> r (), lfArgs ); const auto alonguArgs = replaceAlong ( lfArgs , along ( u )); const auto alongvArgs = replaceAlong ( lfArgs , along ( v )); const auto argsForDyzalongv_xArgs = replaceAlong ( argsForDyz , along ( v_x )); // (19) const auto argsForDyzalongu_xArgs = replaceAlong ( argsForDyz , along ( u_x )); const auto u_xyzAlongv = evaluateDerivativeImpl ( this -> l (), alongvArgs ); // (20) const auto v_xyzAlongu = evaluateDerivativeImpl ( this -> r (), alonguArgs ); const auto u_yzAlongvx = evaluateDerivativeImpl ( this -> l (), argsForDyzalongv_xArgs ); // (21) const auto v_yzAlongux = evaluateDerivativeImpl ( this -> r (), argsForDyzalongu_xArgs ); return Ikarus :: eval ( u_xyzAlongv + transpose ( u_xy ) * v_z + transpose ( u_xz ) * v_y + v_yzAlongux + u_yzAlongvx + transpose ( v_xz ) * u_y + transpose ( v_xy ) * u_z + v_xyzAlongu ); } else if constexpr ( LFArgs :: hasOneSpatialAll ) { // (22) const auto & alongMatrix = std :: get < 0 > ( lfArgs . alongArgs . args ); // (23) const auto uTimesA = eval ( u * alongMatrix ); const auto vTimesA = eval ( v * alongMatrix ); const auto & [ gradu , u_c0 , u_c1 ] = evaluateFirstOrderDerivativesImpl ( this -> l (), lfArgs ); // (24) const auto & [ gradv , v_c0 , v_c1 ] = evaluateFirstOrderDerivativesImpl ( this -> r (), lfArgs ); const auto & [ gradu_c0 , gradu_c1 ] = evaluateSecondOrderDerivativesImpl ( this -> l (), lfArgs ); // (25) const auto & [ gradv_c0 , gradv_c1 ] = evaluateSecondOrderDerivativesImpl ( this -> r (), lfArgs ); const auto graduTimesA = ( gradu * alongMatrix . transpose ()). eval (); const auto gradvTimesA = ( gradv * alongMatrix . transpose ()). eval (); const auto argsForDyz = lfArgs . extractSecondWrtArgOrFirstNonSpatial (); const auto alonguAArgs = replaceAlong ( lfArgs , along ( uTimesA )); const auto alongvAArgs = replaceAlong ( lfArgs , along ( vTimesA )); const auto alonggraduTimesAArgs = replaceAlong ( argsForDyz , along ( graduTimesA )); const auto alonggradvTimesAArgs = replaceAlong ( argsForDyz , along ( gradvTimesA )); const auto u_xyzAlongv = evaluateDerivativeImpl ( this -> l (), alongvAArgs ); const auto v_xyzAlongu = evaluateDerivativeImpl ( this -> r (), alonguAArgs ); const auto v_c0c1AlongGraduTimesA = evaluateDerivativeImpl ( this -> r (), alonggraduTimesAArgs ); const auto u_c0c1AlongGradvTimesA = evaluateDerivativeImpl ( this -> l (), alonggradvTimesAArgs ); decltype ( eval ( u_xyzAlongv )) res ; res = u_xyzAlongv + v_xyzAlongu + v_c0c1AlongGraduTimesA + u_c0c1AlongGradvTimesA ; for ( int i = 0 ; i < gridDim ; ++ i ) res += ( transpose ( u_c1 ) * gradv_c0 [ i ] + transpose ( v_c1 ) * gradu_c0 [ i ] + transpose ( v_c0 ) * gradu_c1 [ i ] + transpose ( u_c0 ) * gradv_c1 [ i ]) * alongMatrix ( 0 , i ); return res ; } } } Compile time branch for first order derivatives Evaluates the derivative of the this->l() wrt. the only derivative inside the localfunction arguments lfArgs . Evaluates the return value and derivatives and function values are combined as dictated by the product rule. Compile time branch for second order derivatives Since we are in the second order derivatives branch, there are 4 case for the evaluation of function. The function value, the function derivative wrt. to the first argument or the second and the function's derivatives wrt. to both arguments. Here, the function evaluateFirstOrderDerivativesImpl returns the derivatives wrt. to the first argument and the second. If we consider the left function as \\(\\boldsymbol{u}(\\boldsymbol{\\xi},\\boldsymbol{u}_I)\\) this calls returns \\begin{flalign*} \\verb+u_x+ &= \\frac{\\partial\\boldsymbol{u}}{\\partial\\boldsymbol{\\xi}} \\quad \\text{or} \\quad \\verb+u_x+ = \\frac{\\partial\\boldsymbol{u}}{\\partial\\xi_0} \\quad \\text{or} \\quad \\verb+u_x+ = \\frac{\\partial\\boldsymbol{u}}{\\partial\\boldsymbol{u}_I}\\\\ \\verb+u_y+ &= \\frac{\\partial\\boldsymbol{u}}{\\partial\\boldsymbol{u}_J} \\end{flalign*} The first one would be returned if the caller uses u . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeff ( i ))); and the second one u . evaluateDerivative ( gpIndex , wrt ( spatial ( 0 ), coeff ( i ))); and the third without any spatial derivative using u . evaluateDerivative ( gpIndex , wrt ( coeff ( i , j ))); Therefore, this function seperates the two wrt. arguments and returns the corresponding first order derivatives. Compile time branch for the case where no spatial derivatives are requested bot only wrt. coefficients is needed. Creates a new argument variable where the along argument is replaced by v . This function evaluates the derivatives of l wrt to both passed wrt arguments. Furthmore, it takes the give along argument since otherwise the returned object would be a 3 dimensional array. If we consider the left function as \\(\\boldsymbol{u}(\\boldsymbol{\\xi},\\boldsymbol{u}_I)\\) and \\(\\boldsymbol{v}\\) of the same size as \\(\\boldsymbol{u}\\) this calls returns \\begin{flalign*} \\verb+u_xyAlongv + &= \\frac{\\partial^2 u_i }{\\partial\\boldsymbol{u}_I\\partial\\boldsymbol{u}_J} v_i \\end{flalign*} This is the same if the user calls u . evaluateDerivative ( gpIndex , wrt ( coeff ( i , j )), along ( v )); Compile time branch for the case where one spatial derivatives and one derivative wrt. coefficients is needed. This function evaluates the derivatives of l wrt to both passed wrt arguments. If we consider the left function as \\(\\boldsymbol{u}(\\boldsymbol{\\xi},\\boldsymbol{u}_I)\\) this calls returns \\begin{flalign*} \\verb+u_xy+ &= \\frac{\\partial^2 \\boldsymbol{u} }{\\partial\\boldsymbol{\\xi}\\partial\\boldsymbol{u}_I} \\quad \\text{or} \\quad \\verb+u_xy+ = \\frac{\\partial^2 \\boldsymbol{u} }{\\partial\\xi_0\\partial\\boldsymbol{u}_I} \\end{flalign*} The first one would be returned if the caller uses u . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeff ( i ))); and the second one u . evaluateDerivative ( gpIndex , wrt ( spatial ( 0 ), coeff ( i ))); In the first case the result is stored in an array. Thus in the first index the derivative wrt. to the first spatial coordinate is stored. Therefore we would have in the code spatialAllCoeffDeriv = u . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeff ( i ))); spatialAllCoeffDeriv [ 0 ] // derivative as in u.evaluateDerivative(gpIndex, wrt(spatial(0),coeff(i))); spatialAllCoeffDeriv [ 1 ] // derivative as in u.evaluateDerivative(gpIndex, wrt(spatial(1),coeff(i))); Compile time branch for the case where one single spatial derivatives and one derivative wrt. coefficients is needed. Compile time branch for the case where all spatial derivatives and one derivative wrt. coefficients is needed. The return type here is an array of single spatial derivatives and each derived wrt. the coefficient. Thus the type inside the array must be deduced here. Compile time branch for third order derivatives Compile time branch for single spatial derivatives To obtain derivatives wrt to the second and third wrt argument we extract here the arguments. E.g. if we have the following request u . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeff ( i , j )), along ( matrix )); this call would extract the arguments as newArgs = \"wrt(coeff(i,j)),along(matrix))\" //THIS IS NO VALID SYNTAX This can be used then as u . evaluateDerivative ( gpIndex , newArgs ); As in the second order derivative case the returns all three first order derivatives. If we would have u . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeff ( i , j )), along ( matrix )); The returned values would be \\begin{flalign*} \\verb+u_x+ &= \\frac{\\partial \\boldsymbol{u} }{\\partial\\boldsymbol{\\xi}} \\\\ \\verb+u_y+ &= \\frac{\\partial \\boldsymbol{u} }{\\partial\\boldsymbol{u}_I} \\\\ \\verb+u_z+ &= \\frac{\\partial \\boldsymbol{u} }{\\partial\\boldsymbol{u}_J} \\end{flalign*} This returns the derivatives wrt to the given spatial direction and wrt to the first and second coefficient. If we would have u . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeff ( i , j )), along ( matrix )); The returned values would be \\begin{flalign*} \\verb+u_xy+ &= \\frac{\\partial^2 \\boldsymbol{u} }{\\partial\\boldsymbol{\\xi}\\partial\\boldsymbol{u}_I} \\\\ \\verb+u_xz+ &= \\frac{\\partial^2 \\boldsymbol{u} }{\\partial\\boldsymbol{\\xi}\\partial\\boldsymbol{u}_J} \\\\ \\end{flalign*} Creates a new argument variable where the along argument is replaced by v_x . This return as the call would be u . evaluateDerivative ( gpIndex , wrt ( spatial ( 0 ), coeff ( i , j ), along ( v )); In mathematical notation this returns \\begin{flalign*} \\verb+u_xyzAlongv + &= \\frac{\\partial^3 u_i }{\\partial \\xi_0\\partial\\boldsymbol{u}_I\\partial\\boldsymbol{u}_J} v_i \\end{flalign*} This return as the call would be v_x = v . evaluateDerivative ( gpIndex , wrt ( spatial ( 0 )); u_yzAlongvx = u . evaluateDerivative ( gpIndex , wrt ( coeff ( i , j ), along ( v_x )); In mathematical notation this returns \\begin{flalign*} \\verb+u_yzAlongvx+ &= \\frac{\\partial^2 u_i }{\\partial\\boldsymbol{u}_I\\partial\\boldsymbol{u}_J} \\left[\\frac{\\partial \\boldsymbol{v}}{\\xi_0}\\right]_i \\end{flalign*} Compile time branch for all spatial derivatives Obtain the along argument give by the caller as in u . evaluateDerivative ( gpIndex , wrt ( spatialAll , coeff ( i , j ), along ( matrix )); As above in the single spatial case As above in the single spatial case If your expression is working you should add it to ikarus/localfunctions/expressions.hh Expression templates are usually used in linear algebra libraries, e.g. Eigen or Blaze . The syntax is similar to the one provided by UML but only acts on local functions. \u21a9 Oliver Sander. DUNE\u2014The Distributed and Unified Numerics Environment . Volume 140. Springer Nature, 2020. URL: https://link.springer.com/book/10.1007/978-3-030-59702-3 . \u21a9 Philipp Grohs, Hanne Hardering, Oliver Sander, and Markus Sprecher. Projection-based finite elements for nonlinear function spaces. SIAM J Numer Anal , 57(1):404\u2013428, 2019. doi:10.1137/18M1176798 . \u21a9","title":"Evaluate underlying functions"},{"location":"01_theory/manifolds/","text":"Manifold elements \u00b6 Introduction \u00b6 Usually optimization problems are defined in terms of some cost function. $$ \\min_{\\boldsymbol{x} \\in \\mathcal{M}} f(\\boldsymbol{x} ) $$ where \\( f: \\mathcal{M} \\rightarrow \\mathbb{R} \\) . Usually \\( \\mathcal{M} \\) is an Euclidean vector space \\( \\mathbb{R}^n \\) . In a finite element context, if we solve e.g. 2d elasticity problems we have a two-dimensional displacement for each node. Thus if we have \\(n \\) nodes we optimize in \\( {\\mathbb{R}^2}^n \\) . For this case the nodal degrees of freedom should be wrapped in Ikarus :: RealTuple < double , 2 > . Another case of optimization is on non-linear manifolds. These arise typically for Cosserat materials \\( \\mathcal{S}\\mathcal{O}(3) \\) , Reissner-Mindlin shells and micromagnetics \\( \\mathcal{S}^{2} \\) or incompressible materials. Interface \u00b6 The general interface of the manifold elements is represented by the following concept. namespace Ikarus :: Concepts { template < typename ManifoldType > concept Manifold = requires ( ManifoldType var , typename ManifoldType :: CorrectionType correction , std :: ostream & s , typename ManifoldType :: CoordinateType value ) { typename ManifoldType :: ctype ; // (1) ManifoldType :: valueSize ; // (2) ManifoldType :: correctionSize ; // (3) typename ManifoldType :: CoordinateType ; // (4) typename ManifoldType :: CorrectionType ; // (5) { var . getValue () } -> std :: convertible_to < typename ManifoldType :: CoordinateType > ; // (6) { var . setValue ( value ) } -> std :: same_as < void > ; // (7) { var += correction }; // (8) { s << var } -> std :: same_as < std :: ostream &> ; }; } The type for the coordinate values usually double . The number of values to store the state of the element. E.g. the three dimensional unit vector needs three entries to store its state. The size of the correction of the element. For the Euclidean space valueSize and correctionSize coincide. But e.g. the three dimensional unit vector needs a two-dimensional correction. (Which lives in the tangent space.) The type to store the element coordinates usually Eigen :: Vector < double , ManifoldType :: valueSize > The type to store the element correction type usually Eigen :: Vector < double , ManifoldType :: correctionSize > Access the underlying coordinates vector of the manifold element. Directly set the value. E.g. set a Ikarus :: UnitVector < double , 3 > a ; a . setValue ( Eigen :: Vector3d :: UnitZ ()); Update the element with a correction vector. E.g. Ikarus :: RealTuple < double , 3 > a ; a += Eigen :: Vector3d :: UnitX (); Ikarus :: UnitVector < double , 3 > b ; b += Eigen :: Vector2d :: UnitX (); Implementations \u00b6 Name Formal definition Notes Header \\(n\\) -th dimensional Euclidean space $$ \\boldsymbol{x} \\in \\mathbb{R}^n $$ realTuple.hh Unit sphere $$ \\boldsymbol{x} \\in \\mathcal{S}^{n-1}, \\quad \\mathcal{S}^{n-1} = \\left\\{ \\boldsymbol{x} \\in \\mathbb{R}^n : \\boldsymbol{x}\\cdot \\boldsymbol{x} = 1 \\right\\} $$ unitVector.hh","title":"Manifolds"},{"location":"01_theory/manifolds/#manifold-elements","text":"","title":"Manifold elements"},{"location":"01_theory/manifolds/#introduction","text":"Usually optimization problems are defined in terms of some cost function. $$ \\min_{\\boldsymbol{x} \\in \\mathcal{M}} f(\\boldsymbol{x} ) $$ where \\( f: \\mathcal{M} \\rightarrow \\mathbb{R} \\) . Usually \\( \\mathcal{M} \\) is an Euclidean vector space \\( \\mathbb{R}^n \\) . In a finite element context, if we solve e.g. 2d elasticity problems we have a two-dimensional displacement for each node. Thus if we have \\(n \\) nodes we optimize in \\( {\\mathbb{R}^2}^n \\) . For this case the nodal degrees of freedom should be wrapped in Ikarus :: RealTuple < double , 2 > . Another case of optimization is on non-linear manifolds. These arise typically for Cosserat materials \\( \\mathcal{S}\\mathcal{O}(3) \\) , Reissner-Mindlin shells and micromagnetics \\( \\mathcal{S}^{2} \\) or incompressible materials.","title":"Introduction"},{"location":"01_theory/manifolds/#interface","text":"The general interface of the manifold elements is represented by the following concept. namespace Ikarus :: Concepts { template < typename ManifoldType > concept Manifold = requires ( ManifoldType var , typename ManifoldType :: CorrectionType correction , std :: ostream & s , typename ManifoldType :: CoordinateType value ) { typename ManifoldType :: ctype ; // (1) ManifoldType :: valueSize ; // (2) ManifoldType :: correctionSize ; // (3) typename ManifoldType :: CoordinateType ; // (4) typename ManifoldType :: CorrectionType ; // (5) { var . getValue () } -> std :: convertible_to < typename ManifoldType :: CoordinateType > ; // (6) { var . setValue ( value ) } -> std :: same_as < void > ; // (7) { var += correction }; // (8) { s << var } -> std :: same_as < std :: ostream &> ; }; } The type for the coordinate values usually double . The number of values to store the state of the element. E.g. the three dimensional unit vector needs three entries to store its state. The size of the correction of the element. For the Euclidean space valueSize and correctionSize coincide. But e.g. the three dimensional unit vector needs a two-dimensional correction. (Which lives in the tangent space.) The type to store the element coordinates usually Eigen :: Vector < double , ManifoldType :: valueSize > The type to store the element correction type usually Eigen :: Vector < double , ManifoldType :: correctionSize > Access the underlying coordinates vector of the manifold element. Directly set the value. E.g. set a Ikarus :: UnitVector < double , 3 > a ; a . setValue ( Eigen :: Vector3d :: UnitZ ()); Update the element with a correction vector. E.g. Ikarus :: RealTuple < double , 3 > a ; a += Eigen :: Vector3d :: UnitX (); Ikarus :: UnitVector < double , 3 > b ; b += Eigen :: Vector2d :: UnitX ();","title":"Interface"},{"location":"01_theory/manifolds/#implementations","text":"Name Formal definition Notes Header \\(n\\) -th dimensional Euclidean space $$ \\boldsymbol{x} \\in \\mathbb{R}^n $$ realTuple.hh Unit sphere $$ \\boldsymbol{x} \\in \\mathcal{S}^{n-1}, \\quad \\mathcal{S}^{n-1} = \\left\\{ \\boldsymbol{x} \\in \\mathbb{R}^n : \\boldsymbol{x}\\cdot \\boldsymbol{x} = 1 \\right\\} $$ unitVector.hh","title":"Implementations"},{"location":"01_theory/nonlinearOperator/","text":"Nonlinear operator \u00b6 The class NonLinearOperator provides a collection of a function and its derivatives, including the dependence on parameters. Let's assume you have a function f(x) and its derivative df(x) . Then, a NonLinearOperator can be constructed as follows: double x = 13 ; auto fvLambda = [ & ]( auto && x ) { return f ( x ); }; auto dfvLambda = [ & ]( auto && x ) { return df ( x ); }; auto nonLinOp = Ikarus :: NonLinearOperator ( linearAlgebraFunctions ( fvLambda , dfvLambda ), parameter ( x )); It is assumed that the second function is the derivative of the first function, the third function is the derivative of the second function (2 nd derivative of the first function), etc. linearAlgebraFunctions(...) and parameter(...) are helper functions. They are necessary to distinguish which argument is a function and which argument is parameter. nonLinOp provides the following features: void updateAll () // (1) void update < n > () // (2) auto & value () // (3) auto & derivative () // (4) auto & secondDerivative () // (5) auto & nthDerivative < n > () // (6) auto & firstParameter () // (7) auto & secondParameter () // (8) auto & nthParameter < n > () // (9) auto & lastParameter () // (10) auto subOperator < n , m ,... > () // (11) Evaluates all functions Evaluates the n-th function in linearAlgebraFunctions(...) . Counting starts from 0 as always in C++. Returns the result of the function evaluation. Returns the result of the evaluation of the first derivative (if the function for the first derivative of passed to the nonlinear Operator at construction.) Returns the result of the evaluation of the second derivative (if the function for the second derivative of passed to the nonlinear Operator at construction.). Returns the result of the evaluation of the n-th derivative (if the function for the third derivative of passed to the nonlinear Operator at construction.). Returns the value of the first parameter. Returns the value of the second parameter (if available). Returns the value of the n-th parameter (if available). Returns the value of the last parameter. Creates a Ikarus::NonLinearOperator with a subset of the derivatives. Example: You have a nonlinear operator with (function, first derivative, second derivative). subOperator<0,1>() then returns a nonlinear operator with (function, first derivative).","title":"NonlinearOperator"},{"location":"01_theory/nonlinearOperator/#nonlinear-operator","text":"The class NonLinearOperator provides a collection of a function and its derivatives, including the dependence on parameters. Let's assume you have a function f(x) and its derivative df(x) . Then, a NonLinearOperator can be constructed as follows: double x = 13 ; auto fvLambda = [ & ]( auto && x ) { return f ( x ); }; auto dfvLambda = [ & ]( auto && x ) { return df ( x ); }; auto nonLinOp = Ikarus :: NonLinearOperator ( linearAlgebraFunctions ( fvLambda , dfvLambda ), parameter ( x )); It is assumed that the second function is the derivative of the first function, the third function is the derivative of the second function (2 nd derivative of the first function), etc. linearAlgebraFunctions(...) and parameter(...) are helper functions. They are necessary to distinguish which argument is a function and which argument is parameter. nonLinOp provides the following features: void updateAll () // (1) void update < n > () // (2) auto & value () // (3) auto & derivative () // (4) auto & secondDerivative () // (5) auto & nthDerivative < n > () // (6) auto & firstParameter () // (7) auto & secondParameter () // (8) auto & nthParameter < n > () // (9) auto & lastParameter () // (10) auto subOperator < n , m ,... > () // (11) Evaluates all functions Evaluates the n-th function in linearAlgebraFunctions(...) . Counting starts from 0 as always in C++. Returns the result of the function evaluation. Returns the result of the evaluation of the first derivative (if the function for the first derivative of passed to the nonlinear Operator at construction.) Returns the result of the evaluation of the second derivative (if the function for the second derivative of passed to the nonlinear Operator at construction.). Returns the result of the evaluation of the n-th derivative (if the function for the third derivative of passed to the nonlinear Operator at construction.). Returns the value of the first parameter. Returns the value of the second parameter (if available). Returns the value of the n-th parameter (if available). Returns the value of the last parameter. Creates a Ikarus::NonLinearOperator with a subset of the derivatives. Example: You have a nonlinear operator with (function, first derivative, second derivative). subOperator<0,1>() then returns a nonlinear operator with (function, first derivative).","title":"Nonlinear operator"},{"location":"01_theory/observer/","text":"Oberserver and Observable \u00b6 To solve situations like \"I want to write an output when the loadstep is completed\", the observer pattern is implemented in Ikarus. To understand it and use it in your implementation, you need to understand three things: IObservable , IObserver and Messages. Messages \u00b6 A message class is a list of possible events that can happen and might be of interest. The messages which are used for nonlinear solvers are listed below as an example. enum class NonLinearSolverMessages { BEGIN , INIT , ITERATION_STARTED , ITERATION_ENDED , RESIDUALNORM_UPDATED , CORRECTIONNORM_UPDATED , SOLUTION_CHANGED , FINISHED_SUCESSFULLY , END }; IObservable \u00b6 A class can be observable. The class then sends notifications when events are happening. To become observable, a class has to inherit from IObservable<MessageType> , e.g. class NewtonRaphson : public IObservable < NonLinearSolverMessages > {...}; To send a notification, the function this->notify(MessageType::Message) is called at the corresponding position in the code. This could be for example this -> notify ( NonLinearSolverMessages :: SOLUTION_CHANGED ); IObserver \u00b6 A class can be an observer. The class is then notified when events are happening and can perform actions. A very simple example is shown below. To become an observer, the class has to inherit from IObserver<MessageType> , where MessageType is the enum of messages that should be used (see above). class OurFirstObserver : public IObserver < NonLinearSolverMessages > { public : void updateImpl ( NonLinearSolverMessages message ) override { if ( message == NonLinearSolverMessages :: ITERATION_STARTED ) std :: cout << \"Yeah, the iteration started. Let's go! \\n \" ; } }; The observer has to implement hat function void updateImpl(MessageType message) . In this function, all actions can be implemented that should be performed when the corresponding message is received. To connect observer and observable, one has to call observalbe.subscribe(MessageType::Message,observer) . Example: Ikarus :: NewtonRaphson nr (...); auto ourSimpleObserver = std :: make_shared < OurFirstObserver > (); nr . subscribe ( NonLinearSolverMessages :: ITERATION_STARTED , ourSimpleObserver ); }; Subscription options and sending data \u00b6 There are a couple of options for the subscription: subscribe ( MessageType :: Message , observer ) // (1) subscribeAll ( observer ) // (2) subscribeAll ({ observer1 , observer2 }) // (3) unSubscribe (...) // (4) Subscribe to one specific message. Subscribe to all messages in the enum. Multiple observers can subscribe at once. Unsubscribe from specific messages or all messages To send a message together with data, the sender (observable) calls this -> notify ( MessageType :: Message , data ); and the receiver (observer) has to implement void updateImpl ( MessageType message , data ) override { To see all available options for data , we refer to the file observer.hh .","title":"Observer and observables"},{"location":"01_theory/observer/#oberserver-and-observable","text":"To solve situations like \"I want to write an output when the loadstep is completed\", the observer pattern is implemented in Ikarus. To understand it and use it in your implementation, you need to understand three things: IObservable , IObserver and Messages.","title":"Oberserver and Observable"},{"location":"01_theory/observer/#messages","text":"A message class is a list of possible events that can happen and might be of interest. The messages which are used for nonlinear solvers are listed below as an example. enum class NonLinearSolverMessages { BEGIN , INIT , ITERATION_STARTED , ITERATION_ENDED , RESIDUALNORM_UPDATED , CORRECTIONNORM_UPDATED , SOLUTION_CHANGED , FINISHED_SUCESSFULLY , END };","title":"Messages"},{"location":"01_theory/observer/#iobservable","text":"A class can be observable. The class then sends notifications when events are happening. To become observable, a class has to inherit from IObservable<MessageType> , e.g. class NewtonRaphson : public IObservable < NonLinearSolverMessages > {...}; To send a notification, the function this->notify(MessageType::Message) is called at the corresponding position in the code. This could be for example this -> notify ( NonLinearSolverMessages :: SOLUTION_CHANGED );","title":"IObservable"},{"location":"01_theory/observer/#iobserver","text":"A class can be an observer. The class is then notified when events are happening and can perform actions. A very simple example is shown below. To become an observer, the class has to inherit from IObserver<MessageType> , where MessageType is the enum of messages that should be used (see above). class OurFirstObserver : public IObserver < NonLinearSolverMessages > { public : void updateImpl ( NonLinearSolverMessages message ) override { if ( message == NonLinearSolverMessages :: ITERATION_STARTED ) std :: cout << \"Yeah, the iteration started. Let's go! \\n \" ; } }; The observer has to implement hat function void updateImpl(MessageType message) . In this function, all actions can be implemented that should be performed when the corresponding message is received. To connect observer and observable, one has to call observalbe.subscribe(MessageType::Message,observer) . Example: Ikarus :: NewtonRaphson nr (...); auto ourSimpleObserver = std :: make_shared < OurFirstObserver > (); nr . subscribe ( NonLinearSolverMessages :: ITERATION_STARTED , ourSimpleObserver ); };","title":"IObserver"},{"location":"01_theory/observer/#subscription-options-and-sending-data","text":"There are a couple of options for the subscription: subscribe ( MessageType :: Message , observer ) // (1) subscribeAll ( observer ) // (2) subscribeAll ({ observer1 , observer2 }) // (3) unSubscribe (...) // (4) Subscribe to one specific message. Subscribe to all messages in the enum. Multiple observers can subscribe at once. Unsubscribe from specific messages or all messages To send a message together with data, the sender (observable) calls this -> notify ( MessageType :: Message , data ); and the receiver (observer) has to implement void updateImpl ( MessageType message , data ) override { To see all available options for data , we refer to the file observer.hh .","title":"Subscription options and sending data"},{"location":"01_theory/overview/","text":"Overview \u00b6 classDiagram GridView <-- Grid GlobalBasis <-- GridView Assembler <-- GlobalBasis NonlinearOperator <-- Assembler Assembler <-- FiniteElement FiniteElement <-- FERequirements FERequirements <-- FErequirementsBuilder ResultRequirements <-- ResultRequirementsBuilder FERequirements <|-- ResultRequirements FiniteElement <-- ResultRequirements FiniteElement <-- Local function Localfunction <-- Localbasis GlobalBasis <--> Localbasis Localfunction <-- Manifold NonlinearSolver <-- NonlinearOperator NonlinearSolver <-- LinearSolver Controlroutine <-- NonlinearSolver VTKWriter <-- Controlroutine DirichletConditions .. Assembler DirichletConditions .. Controlroutine Controlroutine <|-- IObservable NonlinearSolver <|-- IObservable Observer ..> IObservable FErequirementsBuilder <-- Affordances Affordances <-- ScalarAffordances Affordances <-- VectorAffordances Affordances <-- MatrixAffordances ResultRequirementsBuilder <-- ResultType class ScalarAffordances{ <<enumeration>> mechanicalPotentialEnergy microMagneticPotentialEnergy ... } class VectorAffordances{ <<enumeration>> forces microMagneticForces ... } class MatrixAffordances{ <<enumeration>> stiffness materialstiffness geometricstiffness mass stiffnessdiffBucklingVector microMagneticHessian ... } class ResultType{ <<enumeration>> noType magnetization gradientNormOfMagnetization vectorPotential divergenceOfVectorPotential BField HField cauchyStress director ... } class Observer{ +update() } class DirichletConditions{ TBA } class IObservable{ +subscribe() +subscribeAll() +unSubscribe() +unSubscribeAll() +notify() } class FERequirements{ +hasAffordance() +getSolution() +getParameter() } class ResultRequirements{ +isResultRequested() +getParameter() } class ResultRequirementsBuilder{ +addAffordance() +insertParameter() +insertGlobalSolution() +addResultRequest() } class FErequirementsBuilder{ +addAffordance() +insertParameter() +insertGlobalSolution() +build() } class Assembler{ +getScalar() +getVector() +getMatrix() +getReducedMatrix() +getReducedVector() +createFullVector() } class GridView{ +elements(gridView) +vertices(gridView) +edges(gridView) +surfaces(gridView) } class Controlroutine{ +run() } class NonlinearSolver{ +setup() +solve() +nonLinearOperator() } class GlobalBasis{ +localView() } class Grid{ +leafGridView() } class FiniteElement{ +calculateScalar() +calculateVector() +calculateMatrix() +calculateAt() } class LinearSolver{ +analyzePattern() +factorize() +compute() +solve() } class NonlinearOperator{ +value() +derivative() +secondDerivative() +nthDerivative<n>() +subOperator() } class Localfunction{ +calculateFunction() +calculateDerivative() +bind() +viewOverIntegrationPoints() } class Localbasis{ +calculateFunction() +evaluateJacobian() +bind() +isBound() +viewOverIntegrationPoints() } class Manifold{ +setValue() +operator+=() +getValue() +size() +size() } click NonlinearOperator href \"../nonlinearOperator/\" click LinearSolver href \"../solvers/#linear-solver\" click NonlinearSolver href \"../solvers/#non-linear-solver\" click FiniteElement href \"../finiteElements/\" click GridView href \"../grid/\" click Grid href \"../grid/\" click Controlroutine href \"../controlRoutines/\" click Assembler href \"../assembler/\" click Localfunction href \"../localFunctions/\" click Manifold href \"../manifolds/\" click Localbasis href \"../localBasis/\" click FERequirements href \"../feRequirements/\" click FErequirementsBuilder href \"../feRequirements/\" click ResultRequirements href \"../feRequirements/#fe-result-requirements\" click ResultRequirementsBuilder href \"../feRequirements/#fe-result-requirements\" click Affordances href \"../feRequirements/\" click ResultType href \"../feRequirements/\" click IObservable href \"../observer/#iobservable\" click Observer href \"../observer/#iobserver\" click GlobalBasis href \"../globalBasis/\"","title":"Overview"},{"location":"01_theory/overview/#overview","text":"classDiagram GridView <-- Grid GlobalBasis <-- GridView Assembler <-- GlobalBasis NonlinearOperator <-- Assembler Assembler <-- FiniteElement FiniteElement <-- FERequirements FERequirements <-- FErequirementsBuilder ResultRequirements <-- ResultRequirementsBuilder FERequirements <|-- ResultRequirements FiniteElement <-- ResultRequirements FiniteElement <-- Local function Localfunction <-- Localbasis GlobalBasis <--> Localbasis Localfunction <-- Manifold NonlinearSolver <-- NonlinearOperator NonlinearSolver <-- LinearSolver Controlroutine <-- NonlinearSolver VTKWriter <-- Controlroutine DirichletConditions .. Assembler DirichletConditions .. Controlroutine Controlroutine <|-- IObservable NonlinearSolver <|-- IObservable Observer ..> IObservable FErequirementsBuilder <-- Affordances Affordances <-- ScalarAffordances Affordances <-- VectorAffordances Affordances <-- MatrixAffordances ResultRequirementsBuilder <-- ResultType class ScalarAffordances{ <<enumeration>> mechanicalPotentialEnergy microMagneticPotentialEnergy ... } class VectorAffordances{ <<enumeration>> forces microMagneticForces ... } class MatrixAffordances{ <<enumeration>> stiffness materialstiffness geometricstiffness mass stiffnessdiffBucklingVector microMagneticHessian ... } class ResultType{ <<enumeration>> noType magnetization gradientNormOfMagnetization vectorPotential divergenceOfVectorPotential BField HField cauchyStress director ... } class Observer{ +update() } class DirichletConditions{ TBA } class IObservable{ +subscribe() +subscribeAll() +unSubscribe() +unSubscribeAll() +notify() } class FERequirements{ +hasAffordance() +getSolution() +getParameter() } class ResultRequirements{ +isResultRequested() +getParameter() } class ResultRequirementsBuilder{ +addAffordance() +insertParameter() +insertGlobalSolution() +addResultRequest() } class FErequirementsBuilder{ +addAffordance() +insertParameter() +insertGlobalSolution() +build() } class Assembler{ +getScalar() +getVector() +getMatrix() +getReducedMatrix() +getReducedVector() +createFullVector() } class GridView{ +elements(gridView) +vertices(gridView) +edges(gridView) +surfaces(gridView) } class Controlroutine{ +run() } class NonlinearSolver{ +setup() +solve() +nonLinearOperator() } class GlobalBasis{ +localView() } class Grid{ +leafGridView() } class FiniteElement{ +calculateScalar() +calculateVector() +calculateMatrix() +calculateAt() } class LinearSolver{ +analyzePattern() +factorize() +compute() +solve() } class NonlinearOperator{ +value() +derivative() +secondDerivative() +nthDerivative<n>() +subOperator() } class Localfunction{ +calculateFunction() +calculateDerivative() +bind() +viewOverIntegrationPoints() } class Localbasis{ +calculateFunction() +evaluateJacobian() +bind() +isBound() +viewOverIntegrationPoints() } class Manifold{ +setValue() +operator+=() +getValue() +size() +size() } click NonlinearOperator href \"../nonlinearOperator/\" click LinearSolver href \"../solvers/#linear-solver\" click NonlinearSolver href \"../solvers/#non-linear-solver\" click FiniteElement href \"../finiteElements/\" click GridView href \"../grid/\" click Grid href \"../grid/\" click Controlroutine href \"../controlRoutines/\" click Assembler href \"../assembler/\" click Localfunction href \"../localFunctions/\" click Manifold href \"../manifolds/\" click Localbasis href \"../localBasis/\" click FERequirements href \"../feRequirements/\" click FErequirementsBuilder href \"../feRequirements/\" click ResultRequirements href \"../feRequirements/#fe-result-requirements\" click ResultRequirementsBuilder href \"../feRequirements/#fe-result-requirements\" click Affordances href \"../feRequirements/\" click ResultType href \"../feRequirements/\" click IObservable href \"../observer/#iobservable\" click Observer href \"../observer/#iobserver\" click GlobalBasis href \"../globalBasis/\"","title":"Overview"},{"location":"01_theory/solvers/","text":"Solvers \u00b6 In Ikarus there are essentially two types of solvers. Linear solver \u00b6 The first are called LinearSolver . These are solver which solve for the vector \\( \\boldsymbol{x} \\) in $$ \\boldsymbol{A} \\boldsymbol{x} = \\boldsymbol{b} $$ where \\(\\boldsymbol{A} \\) is some matrix and \\(\\boldsymbol{b}\\) is some vector. These solvers can be direct or iterative. Furthermore, they depend on the underlying structure of the matrix \\(\\boldsymbol{A} \\) . I.e. if it is stored in dense or in a sparse format. Currently, we only support the linear solvers provided by the Eigen library. Linear solvers can be constructed by calling the constructor ILinearSolver ( const SolverTypeTag & solverTypeTag ) There exits an enum type SolverTypeTag with the following values 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 enum class SolverTypeTag { si_ConjugateGradient , si_LeastSquaresConjugateGradient , si_BiCGSTAB , sd_SimplicialLLT , sd_SimplicialLDLT , sd_SparseLU , sd_SparseQR , sd_CholmodSupernodalLLT , sd_UmfPackLU , sd_SuperLU , d_PartialPivLU , d_FullPivLU , d_HouseholderQR , d_ColPivHouseholderQR , d_FullPivHouseholderQR , d_CompleteOrthogonalDecomposition , d_LLT , d_LDLT , }; The prefixes s_ and d_ indicate wether the linear solver can be used for dense or sparse matrices. Furthermore, there is a second prefix for sparse solvers 1 d and i for direct solvers and for iterative solvers. Thus, using si_ConjugateGradient means that this solver is for sparse matrices and is an iterative solver. The naming of the solvers is the same as in Eigen. For more details on the solvers we refer to Eigen's documentation for dense decompositions and to Eigen's documentation for sparse decompositions . Interface \u00b6 Similar to Eigen's interface the following function are provided void analyzePattern ( const MatrixType & A ); // (1) void factorize ( const MatrixType & A ); // (2) ILinearSolver & compute ( const MatrixType & A ); // (3) void solve ( Eigen :: VectorX < ScalarType >& x , const Eigen :: VectorX < ScalarType >& b ); // (4) If the matrix is sparse Eigen can collect information on the sparsity pattern of the matrix for faster a faster solve step. This pattrern does not change if you change the values of the non-zero entries. This method applies some decomposition for direct solvers e.g. LU decomposition. For iterative solvers the method is a noOp. Compute simply calls 'analyzePattern' and 'factorize'. Solves the problem and stores the result in x . Tip If your algorithm in mind does rely on special features of some linear solver then you have to directly use this solver. E.g. if you need the .determinant() method of Eigen::SimplicialLDLT you need to directly use it since ILinearSolver does not support this method. Nonlinear solver \u00b6 Non-linear solvers are usually used to solve some optimization problem, e.g. root-finding or minimization problems \\begin{align} \\boldsymbol{R}(\\boldsymbol{x}) \\stackrel{!}{=} \\boldsymbol{0} \\quad \\text{or} \\quad \\min_{\\boldsymbol{x} \\in \\mathcal{M}} f(\\boldsymbol{x} ) \\end{align} Interface \u00b6 void setup ( const NewtonRaphsonSettings & p_settings ); // (1) SolverInformation solve ( const SolutionType & dx_predictor = NoPredictor {}); // (2) auto & nonLinearOperator (); // (3) With this function several properties of the nonlinear solver can be set. E.g. residual tolerance or maximum number of iterations. Solves the non-linear problem. One can pass an initial guess to the function. Otherwise the zero vector is assumed. It returns SolverInformation which contains information on the sucess of the solution step and other information as the needed iterations. Simply returns the underlying nonLinearOperator , see Link Note To easy the construction process the Nonlinear solver can provide a method make[...] which allows shorter syntax, since no std::shared_ptr has to be constructed and specifying all template arguments. The construction of the nonlinear solvers can be very different. Therefore we do not impose an interface for the constructors. Implementations \u00b6 Name Purpose Constraints on nonlinear operator Header Properties Newton-Raphson Root finding Value and gradient newtonRaphson.hh Locally quadratic convergence Trust-Region Minimization Value, gradient and Hessian trustRegion.hh Globally convergent and locally quadratic convergence To see the Newton-Raphson we refer to the tests inside nonLinearOperatorTest.cpp and for trust region trustRegionTest.cpp . Dense solver are currently all direct solvers. Therefore, we do not distinguish them. \u21a9","title":"Solvers"},{"location":"01_theory/solvers/#solvers","text":"In Ikarus there are essentially two types of solvers.","title":"Solvers"},{"location":"01_theory/solvers/#linear-solver","text":"The first are called LinearSolver . These are solver which solve for the vector \\( \\boldsymbol{x} \\) in $$ \\boldsymbol{A} \\boldsymbol{x} = \\boldsymbol{b} $$ where \\(\\boldsymbol{A} \\) is some matrix and \\(\\boldsymbol{b}\\) is some vector. These solvers can be direct or iterative. Furthermore, they depend on the underlying structure of the matrix \\(\\boldsymbol{A} \\) . I.e. if it is stored in dense or in a sparse format. Currently, we only support the linear solvers provided by the Eigen library. Linear solvers can be constructed by calling the constructor ILinearSolver ( const SolverTypeTag & solverTypeTag ) There exits an enum type SolverTypeTag with the following values 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 enum class SolverTypeTag { si_ConjugateGradient , si_LeastSquaresConjugateGradient , si_BiCGSTAB , sd_SimplicialLLT , sd_SimplicialLDLT , sd_SparseLU , sd_SparseQR , sd_CholmodSupernodalLLT , sd_UmfPackLU , sd_SuperLU , d_PartialPivLU , d_FullPivLU , d_HouseholderQR , d_ColPivHouseholderQR , d_FullPivHouseholderQR , d_CompleteOrthogonalDecomposition , d_LLT , d_LDLT , }; The prefixes s_ and d_ indicate wether the linear solver can be used for dense or sparse matrices. Furthermore, there is a second prefix for sparse solvers 1 d and i for direct solvers and for iterative solvers. Thus, using si_ConjugateGradient means that this solver is for sparse matrices and is an iterative solver. The naming of the solvers is the same as in Eigen. For more details on the solvers we refer to Eigen's documentation for dense decompositions and to Eigen's documentation for sparse decompositions .","title":"Linear solver"},{"location":"01_theory/solvers/#interface","text":"Similar to Eigen's interface the following function are provided void analyzePattern ( const MatrixType & A ); // (1) void factorize ( const MatrixType & A ); // (2) ILinearSolver & compute ( const MatrixType & A ); // (3) void solve ( Eigen :: VectorX < ScalarType >& x , const Eigen :: VectorX < ScalarType >& b ); // (4) If the matrix is sparse Eigen can collect information on the sparsity pattern of the matrix for faster a faster solve step. This pattrern does not change if you change the values of the non-zero entries. This method applies some decomposition for direct solvers e.g. LU decomposition. For iterative solvers the method is a noOp. Compute simply calls 'analyzePattern' and 'factorize'. Solves the problem and stores the result in x . Tip If your algorithm in mind does rely on special features of some linear solver then you have to directly use this solver. E.g. if you need the .determinant() method of Eigen::SimplicialLDLT you need to directly use it since ILinearSolver does not support this method.","title":"Interface"},{"location":"01_theory/solvers/#nonlinear-solver","text":"Non-linear solvers are usually used to solve some optimization problem, e.g. root-finding or minimization problems \\begin{align} \\boldsymbol{R}(\\boldsymbol{x}) \\stackrel{!}{=} \\boldsymbol{0} \\quad \\text{or} \\quad \\min_{\\boldsymbol{x} \\in \\mathcal{M}} f(\\boldsymbol{x} ) \\end{align}","title":"Nonlinear solver"},{"location":"01_theory/solvers/#interface_1","text":"void setup ( const NewtonRaphsonSettings & p_settings ); // (1) SolverInformation solve ( const SolutionType & dx_predictor = NoPredictor {}); // (2) auto & nonLinearOperator (); // (3) With this function several properties of the nonlinear solver can be set. E.g. residual tolerance or maximum number of iterations. Solves the non-linear problem. One can pass an initial guess to the function. Otherwise the zero vector is assumed. It returns SolverInformation which contains information on the sucess of the solution step and other information as the needed iterations. Simply returns the underlying nonLinearOperator , see Link Note To easy the construction process the Nonlinear solver can provide a method make[...] which allows shorter syntax, since no std::shared_ptr has to be constructed and specifying all template arguments. The construction of the nonlinear solvers can be very different. Therefore we do not impose an interface for the constructors.","title":"Interface"},{"location":"01_theory/solvers/#implementations","text":"Name Purpose Constraints on nonlinear operator Header Properties Newton-Raphson Root finding Value and gradient newtonRaphson.hh Locally quadratic convergence Trust-Region Minimization Value, gradient and Hessian trustRegion.hh Globally convergent and locally quadratic convergence To see the Newton-Raphson we refer to the tests inside nonLinearOperatorTest.cpp and for trust region trustRegionTest.cpp . Dense solver are currently all direct solvers. Therefore, we do not distinguish them. \u21a9","title":"Implementations"},{"location":"02_gallery/gallery/","text":"Gallery \u00b6 Micromagnetostatic simulation with magnetization \\( \\boldsymbol{m} \\in \\mathcal{S}^{2} \\) and the magnetic vector potential \\( \\boldsymbol{A} \\in \\mathbb{R}^3 \\). Inside the sphere the free field is discretized and in the center a thin cylindrical magnetic material is place. The B-Field magnitude is indicated by the color. Furthermore, the magnetization vectors inside the magnetic material are shown which indicate the curling mode of the magnet.","title":"Gallery"},{"location":"02_gallery/gallery/#gallery","text":"Micromagnetostatic simulation with magnetization \\( \\boldsymbol{m} \\in \\mathcal{S}^{2} \\) and the magnetic vector potential \\( \\boldsymbol{A} \\in \\mathbb{R}^3 \\). Inside the sphere the free field is discretized and in the center a thin cylindrical magnetic material is place. The B-Field magnitude is indicated by the color. Furthermore, the magnetization vectors inside the magnetic material are shown which indicate the curling mode of the magnet.","title":"Gallery"},{"location":"99_Literature/99_Literature/","text":"Literature \u00b6 Robert C Martin. Clean Code . Pearson Education, 2008. \u21a9 Erich Gamma, Richard Helm, Ralph Johnson, Ralph E Johnson, John Vlissides, and others. Design patterns: elements of reusable object-oriented software . Pearson Deutschland GmbH, 1995. \u21a9 Martin Reddy. API Design for C++ . Elsevier, 2011. \u21a9 Scott Meyers. Effective C++: 55 specific ways to improve your programs and designs . Pearson Education, 2005. \u21a9 Scott Meyers. More Effective C++: 35 New Ways to Improve Your Programs and Designs, PDF Version . Pearson Education, 1995. \u21a9 Alexander M\u00fcller and Manfred Bischoff. A consistent finite element formulation of the geometrically non-linear reissner-mindlin shell model. Archives of Computational Methods in Engineering , pages 1\u201347, 2022. doi:10.1007/s11831-021-09702-7 . \u21a9 J. Kiendl, K.-U. Bletzinger, J. Linhard, and R. W\u00fcchner. Isogeometric shell analysis with kirchhoff\u2013love elements. Computer Methods in Applied Mechanics and Engineering , 198(49):3902\u20133914, 2009. doi:10.1016/j.cma.2009.08.013 . \u21a9 Oliver Sander. DUNE\u2014The Distributed and Unified Numerics Environment . Volume 140. Springer Nature, 2020. URL: https://link.springer.com/book/10.1007/978-3-030-59702-3 . \u21a9 Philipp Grohs, Hanne Hardering, Oliver Sander, and Markus Sprecher. Projection-based finite elements for nonlinear function spaces. SIAM J Numer Anal , 57(1):404\u2013428, 2019. doi:10.1137/18M1176798 . \u21a9","title":"Literature"},{"location":"99_Literature/99_Literature/#literature","text":"Robert C Martin. Clean Code . Pearson Education, 2008. \u21a9 Erich Gamma, Richard Helm, Ralph Johnson, Ralph E Johnson, John Vlissides, and others. Design patterns: elements of reusable object-oriented software . Pearson Deutschland GmbH, 1995. \u21a9 Martin Reddy. API Design for C++ . Elsevier, 2011. \u21a9 Scott Meyers. Effective C++: 55 specific ways to improve your programs and designs . Pearson Education, 2005. \u21a9 Scott Meyers. More Effective C++: 35 New Ways to Improve Your Programs and Designs, PDF Version . Pearson Education, 1995. \u21a9 Alexander M\u00fcller and Manfred Bischoff. A consistent finite element formulation of the geometrically non-linear reissner-mindlin shell model. Archives of Computational Methods in Engineering , pages 1\u201347, 2022. doi:10.1007/s11831-021-09702-7 . \u21a9 J. Kiendl, K.-U. Bletzinger, J. Linhard, and R. W\u00fcchner. Isogeometric shell analysis with kirchhoff\u2013love elements. Computer Methods in Applied Mechanics and Engineering , 198(49):3902\u20133914, 2009. doi:10.1016/j.cma.2009.08.013 . \u21a9 Oliver Sander. DUNE\u2014The Distributed and Unified Numerics Environment . Volume 140. Springer Nature, 2020. URL: https://link.springer.com/book/10.1007/978-3-030-59702-3 . \u21a9 Philipp Grohs, Hanne Hardering, Oliver Sander, and Markus Sprecher. Projection-based finite elements for nonlinear function spaces. SIAM J Numer Anal , 57(1):404\u2013428, 2019. doi:10.1137/18M1176798 . \u21a9","title":"Literature"},{"location":"documentation/BuildTheDocumentationLocally/","text":"How to edit this documentation \u00b6 Prerequisites \u00b6 Ikarus cloned on your computer, see the download page . Preview the documentation locally \u00b6 Changing cmake option: E.g. In Clion: Open File --> Settings --> Build,Execution,Deployment --> Cmake Add -DBUILD_DOCS=TRUE to your cmake options Choose target localSite and build it (click on the hammer) After a couple of seconds, build messages should appear which look similar to the picture below. Click on Services in the footer, double click on Docker and unfold Containers . There should be one container with a blue box while the other containers have a blue box with a white square inside (see figure below). In this example, the container we are looking for is elegant_bassi . The name will be different on your computer, the relevant criterion for finding the container is the blue box. Click on the container with the blue box and navigate to Port Bindings . Add a new port by clicking on + , activate Host port under Modifiy options and enter 8000 in both fields (see image below). Confirm with OK . Click on Save in the lower right corner. This will restart the container. Messages will appear saying that the build failed. These messages can be ignored. The build process restarts automatically. After a couple of seconds, Click on this link . Now you should see a live preview of the documentation in your browser You can edit the documentation in CLion. STRG + s saves the documentation and updates it in your browser window. Cancel the build process to stop the live preview. To restart the live preview, you will have to modify the container settings again. Therefore, it is recommended to stop the live preview only after you finished working on the documentation.","title":"Build the documentation locally"},{"location":"documentation/BuildTheDocumentationLocally/#how-to-edit-this-documentation","text":"","title":"How to edit this documentation"},{"location":"documentation/BuildTheDocumentationLocally/#prerequisites","text":"Ikarus cloned on your computer, see the download page .","title":"Prerequisites"},{"location":"documentation/BuildTheDocumentationLocally/#preview-the-documentation-locally","text":"Changing cmake option: E.g. In Clion: Open File --> Settings --> Build,Execution,Deployment --> Cmake Add -DBUILD_DOCS=TRUE to your cmake options Choose target localSite and build it (click on the hammer) After a couple of seconds, build messages should appear which look similar to the picture below. Click on Services in the footer, double click on Docker and unfold Containers . There should be one container with a blue box while the other containers have a blue box with a white square inside (see figure below). In this example, the container we are looking for is elegant_bassi . The name will be different on your computer, the relevant criterion for finding the container is the blue box. Click on the container with the blue box and navigate to Port Bindings . Add a new port by clicking on + , activate Host port under Modifiy options and enter 8000 in both fields (see image below). Confirm with OK . Click on Save in the lower right corner. This will restart the container. Messages will appear saying that the build failed. These messages can be ignored. The build process restarts automatically. After a couple of seconds, Click on this link . Now you should see a live preview of the documentation in your browser You can edit the documentation in CLion. STRG + s saves the documentation and updates it in your browser window. Cancel the build process to stop the live preview. To restart the live preview, you will have to modify the container settings again. Therefore, it is recommended to stop the live preview only after you finished working on the documentation.","title":"Preview the documentation locally"},{"location":"documentation/howToEdit/","text":"How to edit this documentation \u00b6 Prerequisites \u00b6 Ikarus cloned on your computer, see the download page . Edit a page \u00b6 Open Ikarus in Clion go the folder docs\\website find the markdown file which corresponds to the page you want to edit Apply your changes (can be done directly in CLion or in external tools e.g. Sublime Text) Create a pull request Once the pull request is accepted, the website is automatically updated Add a new page \u00b6 Open Ikarus in Clion go the folder docs\\website and create a new markdown-File, e.g. MyAdditionalPage.md Open the file docs\\mkdocs.yml Find the navigation section which starts with # Navigation The navigation section describes the navigation on the left side of the website. Add MyAdditionalPage.md where you want it to appear Create a pull request Once the pull request is accepted, the website is automatically updated Insert a latex formula \u00b6 $$ \\mathbf{X} \\left( \\xi,\\eta \\right) = \\begin{bmatrix} \\xi^2 \\\\ 5\\xi\\eta \\end{bmatrix} $$ is compiled to \\[ \\mathbf{X} \\left( \\xi,\\eta \\right) = \\begin{bmatrix} \\xi^2 \\\\ 5\\xi\\eta \\end{bmatrix} \\] Insert C++ code \u00b6 The C++ code: double complicatedCalculation ( double number , double anotherNumber ) { return number * anotherNumber ; }; How it needs to be written in markdown: ```cpp double complicatedCalculation(double number, double anotherNumber) { return number*anotherNumber; }; ``` Insert a table \u00b6 Look at the markdown file of this page to see how a table can be inserted. Grid Entity Interface GridViewType leafGridView () GridViewType levelGridView ( int levl ) Insert a warning Note that the four spaces at the beginning of this line are essential for the warning to be displayed correctly. References For available features in the documentation see Mkdocs-Material and Mkdocs .","title":"How to edit the documentation"},{"location":"documentation/howToEdit/#how-to-edit-this-documentation","text":"","title":"How to edit this documentation"},{"location":"documentation/howToEdit/#prerequisites","text":"Ikarus cloned on your computer, see the download page .","title":"Prerequisites"},{"location":"documentation/howToEdit/#edit-a-page","text":"Open Ikarus in Clion go the folder docs\\website find the markdown file which corresponds to the page you want to edit Apply your changes (can be done directly in CLion or in external tools e.g. Sublime Text) Create a pull request Once the pull request is accepted, the website is automatically updated","title":"Edit a page"},{"location":"documentation/howToEdit/#add-a-new-page","text":"Open Ikarus in Clion go the folder docs\\website and create a new markdown-File, e.g. MyAdditionalPage.md Open the file docs\\mkdocs.yml Find the navigation section which starts with # Navigation The navigation section describes the navigation on the left side of the website. Add MyAdditionalPage.md where you want it to appear Create a pull request Once the pull request is accepted, the website is automatically updated","title":"Add a new page"},{"location":"documentation/howToEdit/#insert-a-latex-formula","text":"$$ \\mathbf{X} \\left( \\xi,\\eta \\right) = \\begin{bmatrix} \\xi^2 \\\\ 5\\xi\\eta \\end{bmatrix} $$ is compiled to \\[ \\mathbf{X} \\left( \\xi,\\eta \\right) = \\begin{bmatrix} \\xi^2 \\\\ 5\\xi\\eta \\end{bmatrix} \\]","title":"Insert a latex formula"},{"location":"documentation/howToEdit/#insert-c-code","text":"The C++ code: double complicatedCalculation ( double number , double anotherNumber ) { return number * anotherNumber ; }; How it needs to be written in markdown: ```cpp double complicatedCalculation(double number, double anotherNumber) { return number*anotherNumber; }; ```","title":"Insert C++ code"},{"location":"documentation/howToEdit/#insert-a-table","text":"Look at the markdown file of this page to see how a table can be inserted. Grid Entity Interface GridViewType leafGridView () GridViewType levelGridView ( int levl ) Insert a warning Note that the four spaces at the beginning of this line are essential for the warning to be displayed correctly. References For available features in the documentation see Mkdocs-Material and Mkdocs .","title":"Insert a table"},{"location":"examples/integrate_pi/","text":"This examples comes from /examples/src/tut_compute-pi0.cpp #include <numbers> #include <dune/alugrid/grid.hh> #include <dune/geometry/quadraturerules.hh> #include <dune/grid/io/file/vtk/vtkwriter.hh> #include <Eigen/Core> #include <Eigen/Dense> #include <ikarus/utils/drawing/griddrawer.hh> int main () { constexpr int gridDim = 2 ; // (1) using Grid = Dune :: ALUGrid < gridDim , 2 , Dune :: simplex , Dune :: conforming > ; auto grid = Dune :: GmshReader < Grid >:: read ( \"../../examples/src/testFiles/circleCoarse.msh\" , false ); auto gridView = grid -> leafGridView (); // (2) draw ( gridView ); /// Calculate area from volume function of elements double area1 = 0.0 ; for ( auto & element : elements ( gridView )) area1 += element . geometry (). volume (); /// Integrate function using integration rule on grid auto f = []( auto && global ) { return sqrt ( global [ 0 ] * global [ 0 ] + global [ 1 ] * global [ 1 ]); }; double area2 = 0.0 ; for ( auto & element : elements ( gridView )) { const auto & rule = Dune :: QuadratureRules < double , 2 >:: rule ( element . type (), 1 , Dune :: QuadratureType :: GaussLegendre ); for ( auto & gp : rule ) // area2 += element.geometry().integrationElement(gp.position()) * gp.weight(); area2 += f ( element . geometry (). global ( gp . position ())) * element . geometry (). integrationElement ( gp . position ()) * gp . weight (); // integrationElement --> JacobiDeterminant } std :: cout << area1 << \" \" << area2 << std :: endl ; /// Naive refinement of grid and compare calculated area to pi for ( int i = 0 ; i < 3 ; ++ i ) { area1 = 0.0 ; grid -> globalRefine ( 1 ); auto gridViewRefined = grid -> leafGridView (); std :: cout << \"This gridview contains: \" ; std :: cout << gridViewRefined . size ( 0 ) << \" elements\" << std :: endl ; draw ( gridViewRefined ); for ( auto & element : elements ( gridViewRefined )) { area1 += element . geometry (). volume (); } std :: cout << area1 << \" \" << std :: numbers :: pi << std :: endl ; } /// write element areas to vtk std :: vector < double > areas ; areas . resize ( gridView . size ( 0 )); auto & indexSet = gridView . indexSet (); for ( auto & ele : elements ( gridView )) areas [ indexSet . index ( ele )] = ele . geometry (). volume (); Dune :: VTKWriter vtkWriter ( gridView ); vtkWriter . addCellData ( areas , \"area\" , 1 ); vtkWriter . write ( \"TestGridEntitites\" ); /// Calculate circumference and compare to pi double circumference = 0.0 ; for ( auto & element : elements ( gridView )) if ( element . hasBoundaryIntersections ()) for ( auto & intersection : intersections ( gridView , element )) if ( intersection . boundary ()) circumference += intersection . geometry (). volume (); std :: cout << circumference << \" \" << std :: numbers :: pi << std :: endl ; } Create ALUGrid from gmsh file. Create leaf grid view of grid","title":"Integrate pi"},{"location":"tutorials/tutorialsOverview/","text":"Tutorials \u00b6 This section explains the practical use of several parts and provides examples that you can use as a starting point for your work. It does not describe the impl theory. of various parts of the code. It is dedicated to users who want to extend or modifiy the implemented functionality or who want to learn more about the impl thoughts and theoretical aspects. If you are rather interested in the theoretical background and implementation details, visit the theory and class reference section. Topics \u00b6 To be added","title":"Overview"},{"location":"tutorials/tutorialsOverview/#tutorials","text":"This section explains the practical use of several parts and provides examples that you can use as a starting point for your work. It does not describe the impl theory. of various parts of the code. It is dedicated to users who want to extend or modifiy the implemented functionality or who want to learn more about the impl thoughts and theoretical aspects. If you are rather interested in the theoretical background and implementation details, visit the theory and class reference section.","title":"Tutorials"},{"location":"tutorials/tutorialsOverview/#topics","text":"To be added","title":"Topics"}]}